{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conditional_gen.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahid1993/colab-notebooks/blob/master/conditional_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_42PJRcysYFA",
        "colab_type": "text"
      },
      "source": [
        "# [Building Gmail style smart compose with a char ngram language model](https://towardsdatascience.com/gmail-style-smart-compose-using-char-n-gram-language-models-a73c09550447)\n",
        "\n",
        "### Let’s build a simple and powerful language model from scratch and use it for text generation.\n",
        "\n",
        "If you are a Gmail user, by now you would have experienced the *smart compose* feature. It’s the new automatic sentence completion feature that takes email productivity to an exciting new level. It was released in Google I/O 2018. \n",
        "\n",
        "## Smart compose is smarter than you think\n",
        "\n",
        "**Whatsapp** offers a predictive text and **Google search** auto completes our queries with trending searches as you type in. Overall both offer a simple **model based prefix search**, i.e the text typed in by the user is used as the prefix to predict the next word the user might want to type (in Whatsapp’s case) or user’s search intent (in the Google search case). **Smart compose** is a nifty extension of predictive text and auto complete, but there is more to it.\n",
        "\n",
        "### Whatsapp Predictive Text\n",
        "Whatsapp predicts the next possible word and presents you with the top 3 possibilities. While it is model based, it only predicts the next word (unigram) or at most the next word pair (a bigram), but nothing further.\n",
        "\n",
        "![](https://miro.medium.com/max/1806/1*yMsFXA67-B8JOn11bOBM3g.png)\n",
        "\n",
        "### Google autocomplete\n",
        "The query autocomplete (shown below) is also a model based solution that factors in the search phrase typed in so far and runs a prefix search on the trending searches.\n",
        "\n",
        "![](https://miro.medium.com/max/654/1*_pJzicw2R8Ki6Y-dYdT-jQ.gif)\n",
        "\n",
        "### Smart compose\n",
        "Word level predictive texts are great, but they are a great fit only where the user inputs come in short spurts. But with emails, the user is going to type in a lot of text in one go across multiple emails. So lesser the user needs to type, the greater the user experience and productivity. Also, In emails if you look close, we end up repeating lot of sentences, from greetings to basic pleasantries to closure notes.\n",
        "\n",
        "Smart compose not only uses the current text, it uses the subject and the previous message (if the user is replying) to complete the sentence for you.\n",
        "\n",
        "### Motivation\n",
        "\n",
        "NMT (Neural Machine Translation) has sort of become the canonical use case for explaining sequence to sequence models (Seq2Seq models). While there is nothing wrong in that, IMHO NMT doesn’t do justice to all the magic the Seq2Seq paradigm can offer. Besides MT (Machine Translation) is not a well solved problem (at least as of this writing). But look at smart email response (Kannan et al., 2016) and smart compose (gmail), they are practical solutions that work really well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FkSKN8VwHFT",
        "colab_type": "text"
      },
      "source": [
        "## Language models, RNNs and Seq2Seq Modelling\n",
        "\n",
        "### Language models: Intuition\n",
        "\n",
        "The modern incarnation of a Language Model (LM) is a critical milestone in the progression of NLP as a field . So, let’s start by understanding the intuition behind a LM.\n",
        "\n",
        "![](https://miro.medium.com/max/1024/1*yxbmLf7Rv9z-bRGThgSaVw.png)\n",
        "\n",
        "LMs learn a representation of a text corpus similar to a word embedding but better one. Now, What do I mean by that ? Simply put, the goal of a LM is to break up a text corpus and assign probabilities to text sequences, typically one word at a time.(but there are other variants).\n",
        "\n",
        "So, how does this work ? For a text sequence _“The dog barked at the stranger”_ in our corpus, a word based LM estimates the probability of P(_“The dog barked at the stranger”_) one word at a time using the chain rule of probability. It starts with the probability of the first word(“The”) and continues with, the probability of second word(“dog”) given the first word(“The”) and then goes on to the probability of the third word given the first & second word and so on. Mathematically speaking the LM estimates the following,\n",
        "\n",
        "![](https://miro.medium.com/max/1338/1*hjhcaY4Rir_kQv5ZNeJIMA.png)\n",
        "\n",
        "Concretely, a LM estimates the following, where n is the number of words.\n",
        "\n",
        "![](https://miro.medium.com/max/1296/1*EbyWjo-Nvmbnbv2-a4opRg.png)\n",
        "\n",
        "LMs have many different use cases. One of it is, A LM can tell how probable a text sequence is for a given corpus. For instance, a text sequence **P(“A dog flew upside down without wings)** will yield a very low probability unless the text corpus came out of some fiction novel. But this use case is less interesting to us. What is more interesting is, LMs are a natural fit for sequence generation (in this case text generation).\n",
        "\n",
        "1. We can ask a LM to generate a random sequence of arbitrary length with or without **prefix** (also referred as **seed** or **prompt** sometimes). The prefix or prompt can be anything, a word or another sequence of arbitrary length. For instance, we can prompt a LM with a word to generate a random sentence or we can prompt a LM with a sentence to generate a sentence or a paragraph. _The special case of generating an arbitrary length sequence given a arbitrary length sequence as input is called **conditioned generation**, as the output is conditioned on the input. That is in fact why this paradigm is called Seq2Seq modelling._ Machine Translation is the canonical example of conditioned generation because it is easy to drive the point to the readers. So, shown below is a layout of a classical Seq2Seq model where _**x1,x2…xn**_ being the input sequence and _**y1,y2..ym**_ being the output sequence. (\\<start> and \\<end> are teacher forcing delimiters)\n",
        "\n",
        "![Layout of an RNN based Conditioned Generator](https://miro.medium.com/max/2236/1*b0ycohanqi_2jYyRMCuh5A.png)\n",
        "\n",
        "2. So if you connect the dots, Gmail smart compose is nothing but a **“conditioned generation”** with the _input sequence = current email message + the subject line + the previous email message (if you are replying) and the output sequence = the predicted sentence completions._ (I encourage you to pause here and try composing a message in gmail to see how conditioned generation works). The below diagram shows one possible smart compose model architecture\n",
        "\n",
        "![Conditioned generation in Smart Compose](https://miro.medium.com/max/2462/1*toRTIkFb9i_MYiIykpqWeA.png)\n",
        "\n",
        "Ok, what does this all has to do with RNNs and Encoder-Decoder architecture, how does this all connect ? Let’s look at them one at a time\n",
        "\n",
        "1.   **How are LMs and RNNs related ?** LMs aren’t new. People have been using a Markov models for learning a LM in the past. But it wasn’t the best choice since it had many disadvantages, the details are out of scope for this post. So, long story short RNNs emerged as the goto architecture to do sequence modelling and hence to do LM, as they come with an array of promises to overcome the shortcomings of Markov models. Especially the fact that RNNs can defy Markov limitation and factor in long range dependencies.\n",
        "\n",
        " 2.   **How RNNs and Conditioned Generation are related?** The below figure shows couple of different Seq2Seq modelling flavours RNNs offer. If you compare the conditioned generator layout above with these images it will be obvious to you, that the many to many **(n:m)** flavour i.e where input sequence length is _not equal_ to output sequence length is exactly same as a conditioned generator. _( For the context of this post we will be considering a RNN based conditioned generators but there are more advanced architectures like **Transformers** to implement conditioned generators)_\n",
        " \n",
        " ![](https://miro.medium.com/max/555/1*kbml6zYermJubzcsbfIYnA.png)\n",
        " \n",
        "3. **How conditioned generators and encoder-decoders are related ?** Conditioned generator is just another name for the Encoder-Decoder architecture, whereas generators, conditioned generators are the terms coming from NLP literature. In fact the term “conditioned generator” explains **“what”** the architecture does and the term **“Encoder-Decoder”** simply names the components in the architecture.\n",
        "\n",
        "Now that we have tied everything together nicely. Let’s grok about how we can implement one such conditioned generator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv53pjKS078j",
        "colab_type": "text"
      },
      "source": [
        "## The Experiment\n",
        "\n",
        "### Synthetic dataset creation\n",
        "\n",
        "I used the [Enron email dataset](https://www.cs.cmu.edu/~enron/) as a source to extract and prepare few email messages for this experiment.\n",
        "\n",
        "### Implementation details\n",
        "\n",
        "Sample of some short messages used in this experiment.\n",
        "\n",
        "![Sample of some short messages used in this experiment.](https://miro.medium.com/max/614/1*3hDYqQxI5ujFs_6ZF-34QQ.png)\n",
        "\n",
        "In gmail sentence completion, you can see the predictions don’t actually wait for you to finish an entire word. So we might need a LM much more granular than the ones at word level, **Hence I chose to build at a char ngram level**. One way to accomplish that is to prepare the dataset as shown below:\n",
        "\n",
        "![](https://miro.medium.com/max/372/1*brangiq3muqzubUee70YXQ.png)\n",
        "\n",
        "Also,  subject text is added (prefixed) to the email body text as a part of data preparation, so a single training record = subject text (if one available) + message text\n",
        "\n",
        "_Again this is purely for the experimental purposes, because with a large corpus this style of data preparation can be very memory intensive as one text sequence turns into multiple sequences with char ngram prefixes._\n",
        "\n",
        "Now how does a char ngram level LM change our Encoder-Decoder architecture ? It doesn’t, architecture would be the same, but how it trains changes (shown below).\n",
        "\n",
        "![Char n-gram conditioning for generation (shown in red)](https://miro.medium.com/max/2464/1*N6zO1d4ccY4b5goeSLJa3Q.png)\n",
        "\n",
        "\n",
        "**Brass tacks:** The architecture choices that worked well were a **BiLSTM Encoder and a LSTM Decoder**. For simplicity I wrote this in Python, Keras.\n",
        "\n",
        "\n",
        "## Future work and possible extensions\n",
        "\n",
        " -   Understand the Perplexity of the above LM.\n",
        " -   Add Attention mechanism.\n",
        " -   Replace LSTMs with Transformers.\n",
        " -   Try longer messages and longer prompts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rqIkznPzTz0",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing Enron Email Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzYmnnl-eGVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To mount Google Drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-iD8N7-F596",
        "colab_type": "code",
        "outputId": "e69420c8-1079-4046-e811-6eedc4f818f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!unzip ./sample_data/enron-email-dataset.zip -d ./sample_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./sample_data/enron-email-dataset.zip\n",
            "  inflating: ./sample_data/emails.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3eWjasEzZRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNsSBHu-zlsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"./sample_data/emails.csv\")\n",
        "pd.set_option('display.max_colwidth',-1)\n",
        "new = data[\"message\"].str.split(\"\\n\", n = 15, expand = True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnugzK2gzm4F",
        "colab_type": "code",
        "outputId": "5803b162-0ad0-4e3c-92ce-a09c15e21214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "new.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.evans@thyme&gt;</td>\n",
              "      <td>Date: Mon, 14 May 2001 16:39:00 -0700 (PDT)</td>\n",
              "      <td>From: phillip.allen@enron.com</td>\n",
              "      <td>To: tim.belden@enron.com</td>\n",
              "      <td>Subject:</td>\n",
              "      <td>Mime-Version: 1.0</td>\n",
              "      <td>Content-Type: text/plain; charset=us-ascii</td>\n",
              "      <td>Content-Transfer-Encoding: 7bit</td>\n",
              "      <td>X-From: Phillip K Allen</td>\n",
              "      <td>X-To: Tim Belden &lt;Tim Belden/Enron@EnronXGate&gt;</td>\n",
              "      <td>X-cc:</td>\n",
              "      <td>X-bcc:</td>\n",
              "      <td>X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail</td>\n",
              "      <td>X-Origin: Allen-P</td>\n",
              "      <td>X-FileName: pallen (Non-Privileged).pst</td>\n",
              "      <td>\\nHere is our forecast\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.evans@thyme&gt;</td>\n",
              "      <td>Date: Fri, 4 May 2001 13:51:00 -0700 (PDT)</td>\n",
              "      <td>From: phillip.allen@enron.com</td>\n",
              "      <td>To: john.lavorato@enron.com</td>\n",
              "      <td>Subject: Re:</td>\n",
              "      <td>Mime-Version: 1.0</td>\n",
              "      <td>Content-Type: text/plain; charset=us-ascii</td>\n",
              "      <td>Content-Transfer-Encoding: 7bit</td>\n",
              "      <td>X-From: Phillip K Allen</td>\n",
              "      <td>X-To: John J Lavorato &lt;John J Lavorato/ENRON@enronXgate@ENRON&gt;</td>\n",
              "      <td>X-cc:</td>\n",
              "      <td>X-bcc:</td>\n",
              "      <td>X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail</td>\n",
              "      <td>X-Origin: Allen-P</td>\n",
              "      <td>X-FileName: pallen (Non-Privileged).pst</td>\n",
              "      <td>\\nTraveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.\\n\\nAs far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.  \\n\\nMy suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                           0  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         15\n",
              "0  Message-ID: <18782981.1075855378110.JavaMail.evans@thyme>  ...  \\nHere is our forecast\\n\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
              "1  Message-ID: <15464986.1075855378456.JavaMail.evans@thyme>  ...  \\nTraveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.\\n\\nAs far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.  \\n\\nMy suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time.\\n\n",
              "\n",
              "[2 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEC0CgIL6Acj",
        "colab_type": "code",
        "outputId": "8f1f4a90-f617-42db-c8d3-2eeab5829c54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "data.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>allen-p/_sent_mail/1.</td>\n",
              "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.evans@thyme&gt;\\nDate: Mon, 14 May 2001 16:39:00 -0700 (PDT)\\nFrom: phillip.allen@enron.com\\nTo: tim.belden@enron.com\\nSubject: \\nMime-Version: 1.0\\nContent-Type: text/plain; charset=us-ascii\\nContent-Transfer-Encoding: 7bit\\nX-From: Phillip K Allen\\nX-To: Tim Belden &lt;Tim Belden/Enron@EnronXGate&gt;\\nX-cc: \\nX-bcc: \\nX-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\\nX-Origin: Allen-P\\nX-FileName: pallen (Non-Privileged).pst\\n\\nHere is our forecast\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>allen-p/_sent_mail/10.</td>\n",
              "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.evans@thyme&gt;\\nDate: Fri, 4 May 2001 13:51:00 -0700 (PDT)\\nFrom: phillip.allen@enron.com\\nTo: john.lavorato@enron.com\\nSubject: Re:\\nMime-Version: 1.0\\nContent-Type: text/plain; charset=us-ascii\\nContent-Transfer-Encoding: 7bit\\nX-From: Phillip K Allen\\nX-To: John J Lavorato &lt;John J Lavorato/ENRON@enronXgate@ENRON&gt;\\nX-cc: \\nX-bcc: \\nX-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\\nX-Origin: Allen-P\\nX-FileName: pallen (Non-Privileged).pst\\n\\nTraveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.\\n\\nAs far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.  \\n\\nMy suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     file                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            message\n",
              "0  allen-p/_sent_mail/1.   Message-ID: <18782981.1075855378110.JavaMail.evans@thyme>\\nDate: Mon, 14 May 2001 16:39:00 -0700 (PDT)\\nFrom: phillip.allen@enron.com\\nTo: tim.belden@enron.com\\nSubject: \\nMime-Version: 1.0\\nContent-Type: text/plain; charset=us-ascii\\nContent-Transfer-Encoding: 7bit\\nX-From: Phillip K Allen\\nX-To: Tim Belden <Tim Belden/Enron@EnronXGate>\\nX-cc: \\nX-bcc: \\nX-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\\nX-Origin: Allen-P\\nX-FileName: pallen (Non-Privileged).pst\\n\\nHere is our forecast\\n\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
              "1  allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.evans@thyme>\\nDate: Fri, 4 May 2001 13:51:00 -0700 (PDT)\\nFrom: phillip.allen@enron.com\\nTo: john.lavorato@enron.com\\nSubject: Re:\\nMime-Version: 1.0\\nContent-Type: text/plain; charset=us-ascii\\nContent-Transfer-Encoding: 7bit\\nX-From: Phillip K Allen\\nX-To: John J Lavorato <John J Lavorato/ENRON@enronXgate@ENRON>\\nX-cc: \\nX-bcc: \\nX-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\\nX-Origin: Allen-P\\nX-FileName: pallen (Non-Privileged).pst\\n\\nTraveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.\\n\\nAs far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.  \\n\\nMy suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time.\\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYNW0xkU6Ie2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"from\"] = new[2]\n",
        "data[\"fromn\"] = new[8]\n",
        "data[\"to\"] = new[3]\n",
        "data[\"ton\"] = new[9]\n",
        "data[\"subject\"] = new[4]\n",
        "data[\"msg\"] = new[15]\n",
        "data.drop(columns =[\"message\"], inplace = True) \n",
        "data.drop(columns =[\"file\"], inplace = True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd5yfsGn6Nyv",
        "colab_type": "code",
        "outputId": "2c694b31-c6e6-498a-f380-d1a2cb28a2ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>fromn</th>\n",
              "      <th>to</th>\n",
              "      <th>ton</th>\n",
              "      <th>subject</th>\n",
              "      <th>msg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: phillip.allen@enron.com</td>\n",
              "      <td>X-From: Phillip K Allen</td>\n",
              "      <td>To: tim.belden@enron.com</td>\n",
              "      <td>X-To: Tim Belden &lt;Tim Belden/Enron@EnronXGate&gt;</td>\n",
              "      <td>Subject:</td>\n",
              "      <td>\\nHere is our forecast\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: phillip.allen@enron.com</td>\n",
              "      <td>X-From: Phillip K Allen</td>\n",
              "      <td>To: john.lavorato@enron.com</td>\n",
              "      <td>X-To: John J Lavorato &lt;John J Lavorato/ENRON@enronXgate@ENRON&gt;</td>\n",
              "      <td>Subject: Re:</td>\n",
              "      <td>\\nTraveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.\\n\\nAs far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.  \\n\\nMy suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            from  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        msg\n",
              "0  From: phillip.allen@enron.com  ...  \\nHere is our forecast\\n\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
              "1  From: phillip.allen@enron.com  ...  \\nTraveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.\\n\\nAs far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.  \\n\\nMy suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time.\\n\n",
              "\n",
              "[2 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbmQc_Ox6Pg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['from'] = data[\"from\"].apply(lambda val: val.replace(\"From:\",''))\n",
        "data['fromn'] = data[\"fromn\"].apply(lambda val: val.replace(\"X-From:\",''))\n",
        "data['to'] = data[\"to\"].apply(lambda val: val.replace(\"To:\",''))\n",
        "data['ton'] = data[\"ton\"].apply(lambda val: val.replace(\"X-To:\",''))\n",
        "data['subject'] = data[\"subject\"].apply(lambda val: val.replace(\"Subject:\",''))\n",
        "data['msg'] = data[\"msg\"].apply(lambda val: val.replace(\"\\n\",' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIqBN7PL6U0v",
        "colab_type": "code",
        "outputId": "0a5e425a-87ab-4e1a-db3f-f00e3a96d882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>fromn</th>\n",
              "      <th>to</th>\n",
              "      <th>ton</th>\n",
              "      <th>subject</th>\n",
              "      <th>msg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>phillip.allen@enron.com</td>\n",
              "      <td>Phillip K Allen</td>\n",
              "      <td>tim.belden@enron.com</td>\n",
              "      <td>Tim Belden &lt;Tim Belden/Enron@EnronXGate&gt;</td>\n",
              "      <td></td>\n",
              "      <td>Here is our forecast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>phillip.allen@enron.com</td>\n",
              "      <td>Phillip K Allen</td>\n",
              "      <td>john.lavorato@enron.com</td>\n",
              "      <td>John J Lavorato &lt;John J Lavorato/ENRON@enronXgate@ENRON&gt;</td>\n",
              "      <td>Re:</td>\n",
              "      <td>Traveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.  As far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.    My suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       from  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  msg\n",
              "0   phillip.allen@enron.com  ...   Here is our forecast                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
              "1   phillip.allen@enron.com  ...   Traveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.  As far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.    My suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time. \n",
              "\n",
              "[2 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKZVxfIo6XEl",
        "colab_type": "code",
        "outputId": "08cc5972-213c-425b-f67e-543a3d3b7410",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "# Lets look only at emails with 100 words or less and that are Non-replies\n",
        "data[(data['msg'].str.len() <100) & ~(data['subject'].str.contains('Re:'))].sample(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>fromn</th>\n",
              "      <th>to</th>\n",
              "      <th>ton</th>\n",
              "      <th>subject</th>\n",
              "      <th>msg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>357346</th>\n",
              "      <td>joe.parks@enron.com</td>\n",
              "      <td>Parks, Joe &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=JPARKS&gt;</td>\n",
              "      <td>frank.hayden@enron.com</td>\n",
              "      <td>Hayden, Frank &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Fhayden&gt;</td>\n",
              "      <td></td>\n",
              "      <td>WHEN WILL WE KNOW HOW THE WINNER IS?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143016</th>\n",
              "      <td>mattias.palm@paconsulting.com</td>\n",
              "      <td>X-To:</td>\n",
              "      <td>Subject: Salmon anyone?</td>\n",
              "      <td>X-cc:</td>\n",
              "      <td>Mime-Version: 1.0</td>\n",
              "      <td>&lt;&lt;laxen.asf&gt;&gt;  /mattias    - laxen.asf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495546</th>\n",
              "      <td>pahlbrand@indy.rr.com</td>\n",
              "      <td>Content-Transfer-Encoding: 7bit</td>\n",
              "      <td>watson@enron.com, kwatson@enron.com, reed@enron.com, reedrev@voyager.net,</td>\n",
              "      <td>X-From: Phil Ahlbrand &lt;pahlbrand@indy.rr.com&gt;</td>\n",
              "      <td>\\treed@enron.com, revdavidreed@aol.com</td>\n",
              "      <td>X-FileName: KWATSON (Non-Privileged).pst  My new e-mail address:  pahlbrand@indy.rr.com .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505064</th>\n",
              "      <td>zionette.vincent@enron.com</td>\n",
              "      <td>Zionette Vincent</td>\n",
              "      <td>Subject: Reschedule - EB3270 - Staff Mtg. (Lunch Provided) (4 June 11:30 AM</td>\n",
              "      <td></td>\n",
              "      <td>CDT)</td>\n",
              "      <td>Brandee w/conf. 5-4013  11:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16684</th>\n",
              "      <td>eric.bass@enron.com</td>\n",
              "      <td>Eric Bass</td>\n",
              "      <td>jason.bass2@compaq.com</td>\n",
              "      <td>Jason.Bass2@COMPAQ.com</td>\n",
              "      <td>computer</td>\n",
              "      <td>option 1 is an extra $600  option 2 is an extra $1300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  from  ...                                                                                        msg\n",
              "357346   joe.parks@enron.com            ...   WHEN WILL WE KNOW HOW THE WINNER IS?                                                    \n",
              "143016   mattias.palm@paconsulting.com  ...   <<laxen.asf>>  /mattias    - laxen.asf                                                  \n",
              "495546   pahlbrand@indy.rr.com          ...  X-FileName: KWATSON (Non-Privileged).pst  My new e-mail address:  pahlbrand@indy.rr.com .\n",
              "505064   zionette.vincent@enron.com     ...   Brandee w/conf. 5-4013  11:15                                                           \n",
              "16684    eric.bass@enron.com            ...   option 1 is an extra $600  option 2 is an extra $1300                                   \n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pic0sVy6b-5",
        "colab_type": "code",
        "outputId": "cf5c001e-5a6d-4cf2-b008-745237d044b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "data.head()['msg']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     Here is our forecast                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
              "1     Traveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.  As far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.    My suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time. \n",
              "2     test successful.  way to go!!!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
              "3     Randy,   Can you send me a schedule of the salary and level of everyone in the  scheduling group.  Plus your thoughts on any changes that need to be made.   (Patti S for example)  Phillip                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
              "4     Let's shoot for Tuesday at 11:45.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
              "Name: msg, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwE8cjrn7JOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = [msg for msg in data[(data['msg'].str.len() <100) & ~(data['subject'].str.contains('Re:'))]['msg']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWfxURtp7KLp",
        "colab_type": "code",
        "outputId": "ad8f36a2-e676-466c-b7f5-006ff7044cc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        }
      },
      "source": [
        "corpus[60:69]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['loan servicing-jessica weeber 800-393-5626 jweeber@spbank.com',\n",
              " 'exit mccollough off 410',\n",
              " ' Life Insurance Banner \\t\\t ',\n",
              " ' My steno is 5318.',\n",
              " 'X-FileName: PALLEN (Non-Privileged).pst  Team Here are my Comments:  ',\n",
              " 'X-FileName: PALLEN (Non-Privileged).pst  Team Here are my comments on the subject Topic.       ',\n",
              " 'X-FileName: PALLEN (Non-Privileged).pst  Team   ',\n",
              " '     - Dailytotal.xls ',\n",
              " ' phillip,  please see attached.     -randy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCxtqjoZ7OMQ",
        "colab_type": "code",
        "outputId": "03417045-4595-4169-dae4-d9a358ddd4ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(corpus)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25810"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bml4t8rhpYNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Taking only as subset of corpus, since it takes lot of time for training\n",
        "corpus = corpus[0:10000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yux4w690psbF",
        "colab_type": "code",
        "outputId": "5a8f96d9-175e-4460-fece-8c53af9c33b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(corpus)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0ZsBrqU7TwL",
        "colab_type": "code",
        "outputId": "2cd6bbf9-28e9-4629-a7f0-7ed121030dfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Start by importing all the things we'll need.\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, CuDNNLSTM, Flatten, TimeDistributed, Dropout, LSTMCell, RNN, Bidirectional, Concatenate, Layer\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.python.keras.utils import tf_utils\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, os \n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_RkYugZ7cig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_special_chars(text, punct):\n",
        "    for p in punct:\n",
        "        text = text.replace(p, '')\n",
        "    return text\n",
        "\n",
        "      \n",
        "def preprocess(data):\n",
        "    output = []\n",
        "    punct = '#$%&*+-/<=>@[\\\\]^_`{|}~\\t\\n'\n",
        "    for line in data:\n",
        "         pline= clean_special_chars(line.lower(), punct)\n",
        "         output.append(pline)\n",
        "    return output  \n",
        "\n",
        "\n",
        "def generate_dataset():\n",
        "  \n",
        "    processed_corpus = preprocess(corpus)    \n",
        "    output = []\n",
        "    for line in processed_corpus:\n",
        "        token_list = line\n",
        "        for i in range(1, len(token_list)):\n",
        "            data = []\n",
        "            x_ngram = '<start> '+ token_list[:i+1] + ' <end>'\n",
        "            y_ngram = '<start> '+ token_list[i+1:] + ' <end>'\n",
        "            data.append(x_ngram)\n",
        "            data.append(y_ngram)\n",
        "            output.append(data)\n",
        "    print(\"Dataset prepared with prefix and suffixes for teacher forcing technique\")\n",
        "    dummy_df = pd.DataFrame(output, columns=['input','output'])\n",
        "    return output, dummy_df            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xrqss6-7kGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LanguageIndex():\n",
        "    def __init__(self, lang):\n",
        "        self.lang = lang\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "    def create_index(self):\n",
        "        for phrase in self.lang:\n",
        "            self.vocab.update(phrase.split(' '))\n",
        "        self.vocab = sorted(self.vocab)\n",
        "        self.word2idx[\"<pad>\"] = 0\n",
        "        self.idx2word[0] = \"<pad>\"\n",
        "        for i,word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = i + 1\n",
        "            self.idx2word[i+1] = word\n",
        "\n",
        "def max_length(t):\n",
        "    return max(len(i) for i in t)\n",
        "\n",
        "def load_dataset():\n",
        "    pairs,df = generate_dataset()\n",
        "    out_lang = LanguageIndex(sp for en, sp in pairs)\n",
        "    in_lang = LanguageIndex(en for en, sp in pairs)\n",
        "    input_data = [[in_lang.word2idx[s] for s in en.split(' ')] for en, sp in pairs]\n",
        "    output_data = [[out_lang.word2idx[s] for s in sp.split(' ')] for en, sp in pairs]\n",
        "\n",
        "    max_length_in, max_length_out = max_length(input_data), max_length(output_data)\n",
        "    input_data = tf.keras.preprocessing.sequence.pad_sequences(input_data, maxlen=max_length_in, padding=\"post\")\n",
        "    output_data = tf.keras.preprocessing.sequence.pad_sequences(output_data, maxlen=max_length_out, padding=\"post\")\n",
        "    return input_data, output_data, in_lang, out_lang, max_length_in, max_length_out, df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBUsKoAB7mIX",
        "colab_type": "code",
        "outputId": "59f08f30-5f75-4ff1-e4de-6b7c30ff0071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_data, teacher_data, input_lang, target_lang, len_input, len_target, df = load_dataset()\n",
        "\n",
        "\n",
        "target_data = [[teacher_data[n][i+1] for i in range(len(teacher_data[n])-1)] for n in range(len(teacher_data))]\n",
        "target_data = tf.keras.preprocessing.sequence.pad_sequences(target_data, maxlen=len_target, padding=\"post\")\n",
        "target_data = target_data.reshape((target_data.shape[0], target_data.shape[1], 1))\n",
        "\n",
        "# Shuffle all of the data in unison. This training set has the longest (e.g. most complicated) data at the end,\n",
        "# so a simple Keras validation split will be problematic if not shuffled.\n",
        "\n",
        "p = np.random.permutation(len(input_data))\n",
        "input_data = input_data[p]\n",
        "teacher_data = teacher_data[p]\n",
        "target_data = target_data[p]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset prepared with prefix and suffixes for teacher forcing technique\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rvl3n_Ry7ozF",
        "colab_type": "code",
        "outputId": "5b78003c-d965-463c-e90d-f0fc637b8748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "BUFFER_SIZE = len(input_data)\n",
        "BATCH_SIZE = 128\n",
        "embedding_dim = 300\n",
        "units = 128\n",
        "vocab_in_size = len(input_lang.word2idx)\n",
        "vocab_out_size = len(target_lang.word2idx)\n",
        "df.iloc[30:65]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>&lt;start&gt;  greg,  h &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; appy bday. email me your phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>&lt;start&gt;  greg,  ha &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ppy bday. email me your phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>&lt;start&gt;  greg,  hap &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; py bday. email me your phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>&lt;start&gt;  greg,  happ &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; y bday. email me your phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>&lt;start&gt;  greg,  happy &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;  bday. email me your phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>&lt;start&gt;  greg,  happy  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; bday. email me your phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>&lt;start&gt;  greg,  happy b &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; day. email me your phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bd &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ay. email me your phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bda &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; y. email me your phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; . email me your phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;  email me your phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday.  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; email me your phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. e &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; mail me your phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. em &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ail me your phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. ema &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; il me your phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. emai &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; l me your phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;  me your phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; me your phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email m &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; e your phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email me &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;  your phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email me  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; your phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email me y &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; our phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email me yo &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ur phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email me you &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; r phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email me your &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;  phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email me your  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; phone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email me your p &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; hone  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email me your ph &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; one  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email me your pho &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ne  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email me your phon &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; e  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email me your phone &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;   and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email me your phone  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email me your phone   &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email me your phone  a &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; nd i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email me your phone  an &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; d i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        input                                                                     output\n",
              "30  <start>  greg,  h <end>                                    <start> appy bday. email me your phone  and i will call you.  keith <end>\n",
              "31  <start>  greg,  ha <end>                                   <start> ppy bday. email me your phone  and i will call you.  keith <end> \n",
              "32  <start>  greg,  hap <end>                                  <start> py bday. email me your phone  and i will call you.  keith <end>  \n",
              "33  <start>  greg,  happ <end>                                 <start> y bday. email me your phone  and i will call you.  keith <end>   \n",
              "34  <start>  greg,  happy <end>                                <start>  bday. email me your phone  and i will call you.  keith <end>    \n",
              "35  <start>  greg,  happy  <end>                               <start> bday. email me your phone  and i will call you.  keith <end>     \n",
              "36  <start>  greg,  happy b <end>                              <start> day. email me your phone  and i will call you.  keith <end>      \n",
              "37  <start>  greg,  happy bd <end>                             <start> ay. email me your phone  and i will call you.  keith <end>       \n",
              "38  <start>  greg,  happy bda <end>                            <start> y. email me your phone  and i will call you.  keith <end>        \n",
              "39  <start>  greg,  happy bday <end>                           <start> . email me your phone  and i will call you.  keith <end>         \n",
              "40  <start>  greg,  happy bday. <end>                          <start>  email me your phone  and i will call you.  keith <end>          \n",
              "41  <start>  greg,  happy bday.  <end>                         <start> email me your phone  and i will call you.  keith <end>           \n",
              "42  <start>  greg,  happy bday. e <end>                        <start> mail me your phone  and i will call you.  keith <end>            \n",
              "43  <start>  greg,  happy bday. em <end>                       <start> ail me your phone  and i will call you.  keith <end>             \n",
              "44  <start>  greg,  happy bday. ema <end>                      <start> il me your phone  and i will call you.  keith <end>              \n",
              "45  <start>  greg,  happy bday. emai <end>                     <start> l me your phone  and i will call you.  keith <end>               \n",
              "46  <start>  greg,  happy bday. email <end>                    <start>  me your phone  and i will call you.  keith <end>                \n",
              "47  <start>  greg,  happy bday. email  <end>                   <start> me your phone  and i will call you.  keith <end>                 \n",
              "48  <start>  greg,  happy bday. email m <end>                  <start> e your phone  and i will call you.  keith <end>                  \n",
              "49  <start>  greg,  happy bday. email me <end>                 <start>  your phone  and i will call you.  keith <end>                   \n",
              "50  <start>  greg,  happy bday. email me  <end>                <start> your phone  and i will call you.  keith <end>                    \n",
              "51  <start>  greg,  happy bday. email me y <end>               <start> our phone  and i will call you.  keith <end>                     \n",
              "52  <start>  greg,  happy bday. email me yo <end>              <start> ur phone  and i will call you.  keith <end>                      \n",
              "53  <start>  greg,  happy bday. email me you <end>             <start> r phone  and i will call you.  keith <end>                       \n",
              "54  <start>  greg,  happy bday. email me your <end>            <start>  phone  and i will call you.  keith <end>                        \n",
              "55  <start>  greg,  happy bday. email me your  <end>           <start> phone  and i will call you.  keith <end>                         \n",
              "56  <start>  greg,  happy bday. email me your p <end>          <start> hone  and i will call you.  keith <end>                          \n",
              "57  <start>  greg,  happy bday. email me your ph <end>         <start> one  and i will call you.  keith <end>                           \n",
              "58  <start>  greg,  happy bday. email me your pho <end>        <start> ne  and i will call you.  keith <end>                            \n",
              "59  <start>  greg,  happy bday. email me your phon <end>       <start> e  and i will call you.  keith <end>                             \n",
              "60  <start>  greg,  happy bday. email me your phone <end>      <start>   and i will call you.  keith <end>                              \n",
              "61  <start>  greg,  happy bday. email me your phone  <end>     <start>  and i will call you.  keith <end>                               \n",
              "62  <start>  greg,  happy bday. email me your phone   <end>    <start> and i will call you.  keith <end>                                \n",
              "63  <start>  greg,  happy bday. email me your phone  a <end>   <start> nd i will call you.  keith <end>                                 \n",
              "64  <start>  greg,  happy bday. email me your phone  an <end>  <start> d i will call you.  keith <end>                                  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C-w5YEB7rme",
        "colab_type": "code",
        "outputId": "a00fac11-34fd-46ae-de47-4f601148767d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        }
      },
      "source": [
        "# Create the Encoder layers first.\n",
        "encoder_inputs = Input(shape=(len_input,))\n",
        "encoder_emb = Embedding(input_dim=vocab_in_size, output_dim=embedding_dim)\n",
        "\n",
        "# Use this if you dont need Bidirectional LSTM\n",
        "# encoder_lstm = CuDNNLSTM(units=units, return_sequences=True, return_state=True)\n",
        "# encoder_out, state_h, state_c = encoder_lstm(encoder_emb(encoder_inputs))\n",
        "\n",
        "encoder_lstm = Bidirectional(CuDNNLSTM(units=units, return_sequences=True, return_state=True))\n",
        "encoder_out, fstate_h, fstate_c, bstate_h, bstate_c = encoder_lstm(encoder_emb(encoder_inputs))\n",
        "state_h = Concatenate()([fstate_h,bstate_h])\n",
        "state_c = Concatenate()([bstate_h,bstate_c])\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "\n",
        "# Now create the Decoder layers.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_emb = Embedding(input_dim=vocab_out_size, output_dim=embedding_dim)\n",
        "decoder_lstm = CuDNNLSTM(units=units*2, return_sequences=True, return_state=True)\n",
        "decoder_lstm_out, _, _ = decoder_lstm(decoder_emb(decoder_inputs), initial_state=encoder_states)\n",
        "# Two dense layers added to this model to improve inference capabilities.\n",
        "decoder_d1 = Dense(units, activation=\"relu\")\n",
        "decoder_d2 = Dense(vocab_out_size, activation=\"softmax\")\n",
        "decoder_out = decoder_d2(Dropout(rate=.2)(decoder_d1(Dropout(rate=.2)(decoder_lstm_out))))\n",
        "\n",
        "\n",
        "# Finally, create a training model which combines the encoder and the decoder.\n",
        "# Note that this model has three inputs:\n",
        "model = Model(inputs = [encoder_inputs, decoder_inputs], outputs= decoder_out)\n",
        "\n",
        "# We'll use sparse_categorical_crossentropy so we don't have to expand decoder_out into a massive one-hot array.\n",
        "# Adam is used because it's, well, the best.\n",
        "\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(), loss=\"sparse_categorical_crossentropy\", metrics=['sparse_categorical_accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 50, 300)      11962500    input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) [(None, 50, 256), (N 440320      embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 300)    14055900    input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 256)          0           bidirectional_1[0][1]            \n",
            "                                                                 bidirectional_1[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 256)          0           bidirectional_1[0][3]            \n",
            "                                                                 bidirectional_1[0][4]            \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_3 (CuDNNLSTM)        [(None, None, 256),  571392      embedding_3[0][0]                \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, None, 256)    0           cu_dnnlstm_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, None, 128)    32896       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, None, 128)    0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, None, 46853)  6044037     dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 33,107,045\n",
            "Trainable params: 33,107,045\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7djduHe7uPB",
        "colab_type": "code",
        "outputId": "16e37f01-a94e-41c5-f270-106f98e6efa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "source": [
        "# Note, we use 20% of our data for validation.\n",
        "epochs = 3\n",
        "history = model.fit([input_data, teacher_data], target_data,\n",
        "                 batch_size= BATCH_SIZE,\n",
        "                 epochs=epochs,\n",
        "                 validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 445939 samples, validate on 111485 samples\n",
            "Epoch 1/3\n",
            "445939/445939 [==============================] - 2140s 5ms/sample - loss: 0.6607 - sparse_categorical_accuracy: 0.9032 - val_loss: 0.3358 - val_sparse_categorical_accuracy: 0.9424\n",
            "Epoch 2/3\n",
            "445939/445939 [==============================] - 2108s 5ms/sample - loss: 0.2897 - sparse_categorical_accuracy: 0.9477 - val_loss: 0.2104 - val_sparse_categorical_accuracy: 0.9631\n",
            "Epoch 3/3\n",
            "445939/445939 [==============================] - 2091s 5ms/sample - loss: 0.2047 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.1654 - val_sparse_categorical_accuracy: 0.9708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp2G6QgE74WX",
        "colab_type": "code",
        "outputId": "68de06d3-f244-4d43-82c6-b121825502de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# Plot the results of the training.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label=\"Training loss\")\n",
        "plt.plot(history.history['val_loss'], label=\"Validation loss\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xt4VPW97/H3b2ZygZALmHBPuAlI\nQDBAubjr1pa2oi3irlqCV6qIddfj7rMf9z613U89p7VnV3dra5/iqYF6bRV27T5Kq9VK620rIAEE\nJQgGhBCuAXIFcpv5nT/WSjKJAQaYZM3l83qeeZhZa83Ml5Xhky+/9VtrjLUWERFJLD6vCxARkehT\nuIuIJCCFu4hIAlK4i4gkIIW7iEgCUriLiCQghbuISAJSuIuIJCCFu4hIAgp49ca5ubl25MiRXr29\niEhc2rBhwxFrbd6ZtvMs3EeOHElpaalXby8iEpeMMXsi2U7DMiIiCUjhLiKSgBTuIiIJSOEuIpKA\nFO4iIglI4S4ikoAU7iIiCSjuwn33keM8/OrHhEL6ekARkVOJu3D/S9lBHntzJ//6hy0EFfAiIt3y\n7AzVc7Xk78fQ2BLikdd30BIM8bMbphDwx93vKBGRHhV34Q5w75yxpPh9PPTqx7QEQzxaXESKAl5E\npF1chjvA3VeMIcVvePDlbTS3bmTpTUWkBfxelyUiEhPiut1dfNlofjR/Iqu3HeKuZzfQ2BL0uiQR\nkZgQ1+EOcMvskfzk6xfz1o4qFj9dyslmBbyISNyHO0DxjAJ+ev0U3tt5hEVPvs/xplavSxIR8VRC\nhDvAddOG84viIkr3VHPrE+9T19jidUkiIp5JmHAHuGbKUJbeWMSWyhpuWb6O2hMKeBFJTgkV7gBz\nJw3h1zdPY9uBem5cvpZjx5u9LklEpNclXLgDzJkwiGW3Taf8cAM3LltLVX2T1yWJiPSqhAx3gMvH\n5fHkos+x5+gJikvWcKiu0euSRER6TcKGO8ClF+by9O0zOFjbyILH17C/5qTXJYmI9IqEDneAGaMG\n8MwdMzna0MyCkjXsPXbC65JERHpcwoc7wLQR/fndnTOpO9nKgsfXsPvIca9LEhHpUUkR7gCTh+fw\n3J0zaWwNsaBkDeWHG7wuSUSkxyRNuANMHJrN83fOIhiC4pK1bD9Y73VJIiI9IqnCHWD84ExW3jUL\nvw8WLltL2f46r0sSEYm6pAt3gDF5/Vi5ZDbpAR8Ll61lS2WN1yWJiERVUoY7wMjcDFbeNZusPgFu\nWraODXuqvS5JRCRqkjbcAfIH9GXlktnkZqZx62/WsW7XUa9LEhGJiojC3Rgz1xiz3RhTboz57im2\n+YYxpswYs9UY81x0y+w5Q3P6sHLJLAZnp7PoyfW8W37E65JERM7bGcPdGOMHlgJXAYXAQmNMYZdt\nxgL3A39nrZ0IfKcHau0xA7PSWbFkNgUD+nL7U+t5a0eV1yWJiJyXSDr3GUC5tXaXtbYZWAHM77LN\nncBSa201gLX2cHTL7Hl5mWk8v2QWY/L6cefTpawuO+R1SSIi5yyScB8G7A17XOkuCzcOGGeMedcY\ns9YYM7e7FzLGLDHGlBpjSquqYq87HpCRyvN3zmLCkEy+9dsNvPrRAa9LEhE5J9E6oBoAxgJXAAuB\nZcaYnK4bWWtLrLXTrbXT8/LyovTW0ZXdN4XfLp7JlPwcvv3cJlZt3u91SSIiZy2ScN8H5Ic9Hu4u\nC1cJrLLWtlhrPwV24IR9XMpMT+GZ22cwfUR/vrNiE3/YUOl1SSIiZyWScF8PjDXGjDLGpALFwKou\n27yI07VjjMnFGabZFcU6e11GWoCnvjmDS8fkct8Lm1m5vsLrkkREInbGcLfWtgL3AK8B24D/tNZu\nNcb80BhzjbvZa8BRY0wZ8AbwL9bauJ803ifVz/LbpnP5uDz+5x8+5Nk1u70uSUQkIsZa68kbT58+\n3ZaWlnry3merqTXIPc9t4vWyQ/zbVyew+LLRXpckIknKGLPBWjv9TNsl9RmqkUoL+HnspqlcffFg\nHnx5G4+9We51SSIipxXwuoB4keL38cviIlL8m3n41e20tFrunXMhxhivSxMR+QyF+1kI+H088o1L\nSPH7+PnqHTQHg9z3lfEKeBGJOQr3s+T3GR6+bjIpfh9L39hJc2uI7109QQEvIjFF4X4OfD7D//mH\nSaQFfCx751NagpYH5hUq4EUkZijcz5ExhgfmFZIa8FHy9i6aWkP8+NpJ+HwKeBHxnsL9PBhjuP+q\ni0j1+/jVG+W0BEM8dN1k/Ap4EfGYwv08GWO478rxpAZ8PPL6DlqCIX52wxQCfs0yFRHvKNyj5N45\nY0nx+3jo1Y9pCYZ4tLiIFAW8iHhE4R5Fd18xhhS/4cGXt9HcupGlNxWRFvB7XZaIJCG1llG2+LLR\n/Gj+RFZvO8Rdz26gsSXodUkikoQU7j3gltkj+cnXL+atHVUsfrqUk80KeBHpXQr3HlI8o4CfXj+F\n93YeYdGT73O8qdXrkkQkiSjce9B104bzaHERpXuqufWJ96lrbPG6JBFJEgr3HjZvylCW3ljElsoa\nblm+jtoTCngR6XkK914wd9IQfn3zNLYdqOfG5Ws5drzZ65JEJMEp3HvJnAmDWHbbdMoPN7CwZC1V\n9U1elyQiCUzh3osuH5fHk4s+R8WxExSXrOFQXaPXJYlIglK497JLL8zl6dtncLC2kQWPr2F/zUmv\nSxKRBKRw98CMUQN45o6ZHG1oZkHJGvYeO+F1SSKSYBTuHpk2oj+/u3MmdSdbWfD4GnYfOe51SSKS\nQBTuHpo8PIfn7pxJY2uIBSVrKD/c4HVJIpIgFO4emzg0mxVLZhEMQXHJWrYfrPe6JBFJAAr3GDBu\nUCYr75qF3wcLl62lbH+d1yWJSJxTuMeIMXn9WLlkNukBHwuXrWVLZY3XJYlIHFO4x5CRuRmsvGs2\nWX0C3LRsHRv2VHtdkojEKYV7jMkf0JeVS2aTm5nGrb9Zx7pdR70uSUTikMI9Bg3N6cPKJbMYnJ3O\noifX8275Ea9LEpE4o3CPUQOz0lmxZDYFA/py+1PreWtHldcliUgcUbjHsLzMNJ5fMosxef248+lS\nVpcd8rokEYkTCvcYNyAjlefvnMWEIZl867cbePWjA16XJCJxIKJwN8bMNcZsN8aUG2O+2836RcaY\nKmPMB+5tcfRLTV7ZfVP47eKZTMnP4dvPbWLV5v1elyQiMe6M4W6M8QNLgauAQmChMaawm01XWmsv\ncW/Lo1xn0stMT+GZ22cwfUR/vrNiE3/YUOl1SSISwyLp3GcA5dbaXdbaZmAFML9ny5LuZKQFeOqb\nM7h0TC73vbCZFe9XeF2SiMSoSMJ9GLA37HGlu6yr64wxW4wxLxhj8rt7IWPMEmNMqTGmtKpKsz/O\nRZ9UP8tvm87l4/L47n99yDNrdntdkojEoGgdUP0jMNJaOxl4HXi6u42stSXW2unW2ul5eXlReuvk\nk57i5/FbpvHlwkH84KWtLH9nl9cliUiMiSTc9wHhnfhwd1k7a+1Ra23bl4IuB6ZFpzw5lbSAn8du\nmsrVFw/mwZe38dib5V6XJCIxJBDBNuuBscaYUTihXgzcGL6BMWaItbZtjt41wLaoVindSvH7+GVx\nESn+zTz86nZaWi33zrkQY4zXpYmIx84Y7tbaVmPMPcBrgB94wlq71RjzQ6DUWrsKuNcYcw3QChwD\nFvVgzRIm4PfxyDcuIcXv4+erd9AcDHLfV8Yr4EWSXCSdO9baV4BXuiz7Qdj9+4H7o1uaRMrvMzx8\n3WRSAz6WvrGT5tYQ37t6ggJeJIlFFO4S+3w+w4+vnUSq38eydz6lJWh5YF6hAl4kSSncE4gxhgfm\nFZIa8FHy9i6aWkP8+NpJ+HwKeJFko3BPMMYY7r/qIlL9Pn71RjnNrSEevn4yfgW8SFJRuCcgYwz3\nXTme1ICPR17fQWsoxM9umELAr+vEiSQLhXsCu3fOWFL8Ph569WNagiEeLS4iRQEvkhQU7gnu7ivG\nkOI3PPjyNppbN7L0piLSAn6vyxKRHqY2Lgksvmw0P5o/kdXbDnHXsxtobAl6XZKI9DCFe5K4ZfZI\nfvL1i3lrRxWLny7lZLMCXiSRKdyTSPGMAn52wxTe23mERU++z/GmVq9LEpEeonBPMl+fOpxHi4so\n3VPNrU+8T11ji9cliUgPULgnoXlThrL0xiK2VNZwy/J11J5QwIskGoV7kpo7aQi/vnka2w7Us3DZ\nWo4db/a6JBGJIoV7EpszYRDLbpvOzqoGFpaspaq+6cxPEpG4oHBPcpePy+PJRZ+j4tgJikvWcKiu\n0euSRCQKFO7CpRfm8vTtMzhY28iCx9ewv+ak1yWJyHlSuAsAM0YN4Jk7ZnK0oZkFJWvYe+yE1yWJ\nyHlQuEu7aSP687s7Z1J3spUFj69h95HjXpckIudI4S6dTB6ew/N3zqKxNcSCkjWUH27wuiQROQcK\nd/mMwqFZrFgyi2AIikvWsv1gvdclichZUrhLt8YNymTlXbPw+2DhsrVs3V/rdUkichYU7nJKY/L6\nsXLJbNIDPm5cto4tlTVelyQiEVK4y2mNzM1g5V2zyeoT4KZl69iwp9rrkkQkAgp3OaP8AX1ZuWQ2\nuZlp3PqbdazbddTrkkTkDBTuEpGhOX1YuWQWg7PTWfTket4tP+J1SSJyGgp3idjArHRWLJlNwYC+\n3P7Uet7aUeV1SSJyCgp3OSt5mWk8v2QWFw7sx51Pl7K67JDXJYlINxTuctYGZKTy3OJZTBiaxbd+\nu4FXPzrgdUki0oXCXc5Jdt8UfnvHDKbk5/Dt5zaxavN+r0sSkTAKdzlnmekpPHP7DKaP6M93Vmzi\nDxsqvS5JRFwKdzkvGWkBnvrmDC4dk8t9L2xmxfsVXpckIijcJQr6pPpZftt0Lh+Xx3f/60OeWbPb\n65JEkl5E4W6MmWuM2W6MKTfGfPc0211njLHGmOnRK1HiQXqKn8dvmcaXCwfxg5e2svydXV6XJJLU\nzhjuxhg/sBS4CigEFhpjCrvZLhP4J2BdtIuU+JAW8PPYTVO5+uLBPPjyNh57s9zrkkSSViSd+wyg\n3Fq7y1rbDKwA5nez3Y+AhwB9CWcSS/H7+GVxEfMvGcrDr27n0dWfYK31uiyRpBNJuA8D9oY9rnSX\ntTPGTAXyrbUvn+6FjDFLjDGlxpjSqiqd3ZioAn4fj3zjEq6fNpyfr97BT/+yXQEv0ssC5/sCxhgf\n8Aiw6EzbWmtLgBKA6dOn6197AvP7DA9fN5nUgI+lb+ykuTXE966egDHG69JEkkIk4b4PyA97PNxd\n1iYTmAS86f7DHQysMsZcY60tjVahEn98PsOPr51Eqt/Hsnc+pSVoeWBeoQJepBdEEu7rgbHGmFE4\noV4M3Ni20lpbC+S2PTbGvAncp2AXAGMMD8wrJDXgo+TtXTS1hvjxtZPw+RTwIj3pjOFurW01xtwD\nvAb4gSestVuNMT8ESq21q3q6SIlvxhjuv+oiUv0+fvVGOc2tIR6+fjJ+BbxIj4lozN1a+wrwSpdl\nPzjFtlecf1mSaIwx3HfleFIDPh55fQetoRA/u2EKAb/OoxPpCed9QFXkbNw7Zywpfh8PvfoxLcEQ\njxYXkaKAF4k6hbv0uruvGEOK3/Dgy9tobt3I0puKSAv4vS5LJKGoZRJPLL5sND+aP5HV2w5x17Mb\naGwJel2SSEJRuItnbpk9kp98/WLe2lHF4qdLOdmsgBeJFoW7eKp4RgE/u2EK7+08wqIn3+d4U6vX\nJYkkBIW7eO7rU4fzaHERpXuqufWJ96lrbPG6JJG4p3CXmDBvylCW3ljElsoablm+jtoTCniR86Fw\nl5gxd9IQfn3zNLYdqGfhsrUcO97sdUkicUvhLjFlzoRBLLttOjurGlhYspaq+iavSxKJSwp3iTmX\nj8vjyUWfo+LYCYpL1nCoTl8RIHK2FO4Sky69MJenb5/BwdpGFjy+hv01J70uSSSuKNwlZs0YNYBn\nF8/k6PFmFpSsYe+xE16XJBI3FO4S06YW9Oe5xbOoO9nKgsfXsPvIca9LEokLCneJeRcPz+b5O2fR\n2BpiQckayg83eF2SSMxTuEtcKByaxYolswiGoLhkLdsP1ntdkkhMU7hL3Bg3KJOVd83C74PikjVs\n3V/rdUkiMUvhLnFlTF4/Vi6ZTZ8UPzcuW8eWyhqvSxKJSQp3iTsjczNYeddssvoEuGnZOjbsqfa6\nJJGYE3/hbq3XFUgMyB/Ql5VLZpObmcatv1nHul1HvS5JJKbEX7h/+HsouQL+++dwbJfX1YiHhub0\nYeWSWQzOTmfRk+t5t/yI1yWJxIz4C/eUvoCB1f8LflkEv74M3v4pHCn3ujLxwMCsdFbeNZsRF/Tl\n9qfW89aOKq9LEokJxno0zDF9+nRbWlp67i9QUwFlq6DsJah831k2cCIUzoeJ10Le+OgUKnGh+ngz\nN/9mHZ8cauCxm6bypcJBXpck0iOMMRustdPPuF3chnu42krY9kcn6CvWAhbyLnKCvnA+DCwEY6Lz\nXhKzak+0cOuT77N1Xy2/urGIuZOGeF2SSNQlV7iHqzsAH//JCfo974INwQVjO4J+8MUK+gRW39jC\noifX88HeGn6+4BKumTLU65JEoip5wz1cw+GOjn73O07Q9x/VEfRDixT0Ceh4Uyu3P7We9buP8fD1\nU7h+2nCvSxKJGoV7V8ePwMcvQ9mLsOstsEHIKXCD/loYNk1Bn0BONge585lS3t15hH//h4spnlHg\ndUkiUaFwP50Tx2D7K05Hv/MNCLVA1nAovMYJ++EzwBd/E4mks8aWIN/67Qbe3F7FD+dP5NbZI70u\nSeS8KdwjdbIGtv/ZDfq/QrAZMofABDfoC2aBz+91lXKOmlqD3PPcJl4vO8S/fXUCiy8b7XVJIudF\n4X4uGutgx2vO0E35amhthH6DYMI8N+gvBX/A6yrlLLUEQ/zTik288uFB/nXueP7xigu9LknknEUa\n7kqqcOlZMPkG59ZUD5/8xenoN/0O1i+Hvrkw4WtO0I+8DPwpXlcsEUjx+/hlcREp/s08/Op2Wlot\n9865EKNjLJLAFO6nkpYJk65zbs3HnU6+7CXY8nvY8BT0GQAXfdU5GDvq7yGQ6nXFchoBv49HvnEJ\nKX4fP1+9g+ZgkPu+Ml4BLwkronA3xswFHgX8wHJr7U+6rP8W8G0gCDQAS6y1ZVGu1TupGR3TJ1tO\nQvlfnaDf+iJsehbSs2H8V531Y74AgTSvK5Zu+H2Gh6+bTGrAx9I3dtLcGuJ7V09QwEtCOuOYuzHG\nD+wAvgxUAuuBheHhbYzJstbWufevAf7RWjv3dK8bk2PuZ6u1yZltU/YifPwKNNVCWhaMv8oN+i9C\nSh+vq5QurLX87z+W8dR7u7lt9ggemDcRn08BL/EhmmPuM4Bya+0u94VXAPOB9nBvC3ZXBpAc1+UN\npMH4uc6ttRk+fcsN+pdhy0pI7QfjrnSC/sIvQ2pfrysWwBjDA/MKSQ34KHl7F83BED++9mIFvCSU\nSMJ9GLA37HElMLPrRsaYbwP/DKQCX+zuhYwxS4AlAAUFCXZSSSAVxn7ZuX3tF/Dp287Qzcd/go/+\n4FzNcuxXnKAf+xVI6+d1xUnNGMP9V11Eqt/Hr94op7nV8vD1k/Er4CVBRDIscz0w11q72H18CzDT\nWnvPKba/EbjSWnvb6V43IYZlIhFsda5xU/aScymE44ch0AfGfsk5GDv2K84sHfHML//6CY+8voP5\nlwzlZzdMIeDXCWwSu6I5LLMPyA97PNxddiorgP8bwesmB38ARl/u3K7+D6hY4wR92Son7P1pcOEc\np6MfNxf65HhdcdK5d85YUvw+Hnr1Y1qCIR4tLiJFAS9xLpJwXw+MNcaMwgn1YuDG8A2MMWOttZ+4\nD78KfIJ8ls8PIz/v3OY+5FyHvuwl57b9FfClOAdhC+c7B2X7DvC64qRx9xVjSPEbHnx5G00tG7j7\nijFMGpZNeorOTpb4FNEZqsaYq4Ff4EyFfMJa+2NjzA+BUmvtKmPMo8CXgBagGrjHWrv1dK+ZNMMy\nkQiFYN8G52Bs2SqorQBfAEZd7gT9RV+DjAu8rjIpPLtmNw+s2krIQorfUDg0m6kFOUwt6M/UEf0Z\nmp2uqZPiKV1+IF5ZC/s3uUH/ElTvBuOHUZe5QT8P+uV5XWVCO9LQxMY91WysqGFjRTVbKmtobAkB\nMCgrzQn6gv5MHZHDxKHq7qV3KdwTgbVwcEvHCVPHdoLxwYi/c4J+wjzIHOx1lQmvJRji4wP1bKyo\nbr/tPXYSgFS/j8KhWe1hP7WgP0NzdG6D9ByFe6KxFg5tdcfoX4QjOwADBbM7gj57mNdVJo3D9Y1s\ncjv7TXtq2FxZQ1Or090PzkpvD/qpI/ozcWgWaQF19xIdCvdEd/jjjqA/7J5Plj/TDfprICf/9M+X\nqGpuDbHtQJ3b2dewcU81+2o6uvtJw7Law35qQX8GZ6d7XLHEK4V7MqnaAdvcWTcHP3SWDZvWcT2c\n/iM9LS9ZHa5r7BT2W/bV0ux290Oz0ylyg35qgTN2nxrQ9Es5M4V7sjq6E7atcsboD3zgLBtySUfQ\nXzDG2/qSWHNriLIDde7B2mo2VdR0dPcBHxcP6zwzZ1CWunv5LIW7ODNtylY5Hf0+d18PutgJ+YnX\nQu5YT8sTOFTX2B72G/ZU89G+OpqDTnc/LKePO4zjBP6EIVnq7kXhLl3U7HXOiC17Efauc5YNLOzo\n6PMu0heEx4Cm1iBb9zvdfdsB2wO1jQCkBXxMHp7N1IL+FLmzcwZmqrtPNgp3ObW6/W7QvwR73gMs\n5I5zg/5aGDRRQR9DDtSeZOOemvZpmFvDuvvh/fu0j9tPHeF097p0QmJTuEtk6g85Y/RlLzkXOLMh\nGDCmo6MfMkVBH2MaW5zuflPbvPs9NRysc7r79BQfk4flUNQ2FbOgP3mZ+vKYRKJwl7PXUOVcorjs\nRfj0HbBBZ6ZNW9APnaqgj1H7a062B/2GimrK9tfSEnT+becPcLr7ae7snIsGZ+rKl3FM4S7n5/hR\n2P6y09HvehNCrZCd3xH0w6aDTwERqxpbgny0r7Y98DdWVHO4vgmAPil+Z+w+bCrmBf3U3ccLhbtE\nz8lq2P5nZ3rlzr9BqAWyhjknSxXOd06eUtDHNGst+2pOts+531RRzdb9dbSGnH//Iy7o2x70Reru\nY5rCXXpGYy1sf9Xp6MtXQ7AJ+g12Ln8w8Vrncgg+nWofDxpbgny4r7Z9KubGihqq3O6+b6q/fWZO\n27z7ARmpHlcsoHCX3tBUDztec8boP3kdWhshI88J+sL5MOLzzpeVSFyw1lJZ3TZ274T9tgMd3f2o\n3AyKCjoO1I4fnKmvJfSAwl16V1MDlL/udPQ7XoOWE9BnAEz4mjO9ctTfgz/F6yrlLJ1sDrKlsqb9\n8sebKqo50tAMQEaqnyn5Oe1XxCzK709/dfc9TuEu3mk+4QzZlL0EO16F5gZIz3G+dKRwPoy+wvlC\ncYk71lr2HjvZ6fLH2w7UE3S7+9G5Ge0nWE0t6M+4Qeruo03hLrGhpdE5CNv2VYJNdZCWDRdd7Qb9\nFyBFZ1nGsxPNrWyp7JiZs6mimqPHne6+X1qAKfkdY/dFBTnk9NUv9vOhcJfY09rkTKsse8mZT99Y\nC6mZMH6uE/QXfglS9EUX8c5aS8WxE2zY03GS1ccH63Cbe8bkZXS6/PHYgf3wqbuPmMJdYltrM+x+\n25le+fGfnOmWKRkw7kon6Md+GVIzvK5SouR4UyubK2uc6+W4oV99ogWAzLQAl7hTMKcWOGP32X11\nfOZUFO4SP4ItsPu/nY5+2x/hxBEI9HECfuK1MPZKSOvndZUSRdZadh890Wka5vaw7v7Cgf06Xf74\nwjx1920U7hKfQkHnYmZlLzpB33AIAunOkE3hfKezT8/2ukrpAQ1NrWzZW9PxBScV1dS0dffpAS7J\n7wj7S/JzyO6TnN29wl3iXyjoXJ647CXnuvT1+8GfCmO+6EyvHH8V9MnxukrpIdZadh053j7nflNF\nNdsP1WOtc4mjsQP7hZ1klcPo3OTo7hXuklhCIahc7wb9S1BXCb4UZ1pl4Xy46KvQd4DXVUoPq29s\nYfPe2vZpmJsqaqg96XT3WekBd9zeCftL8nPITE+87l7hLonLWti30Rm6KXsRairAF3BOlCqc78yn\nz8j1ukrpBaGQ2927J1ht3FPDjsMd3f24gZnOCVZu6I/Jy8DE+ZVNFe6SHKx1viu27CVn5k31p2B8\nMPLzTtBPuAb6DfS6SulFdY0tbN5b0+kLTuobWwHI7pPS6RIKU/Kz4667V7hL8rEWDn3UEfRHPwEM\njPg7N+jnQdYQr6uUXhYKWXZWNXS6/PEnhxsAp7sfPyiz0+WPR+XGdnevcJfkZi0c3tYxRl+1DTDO\n5YkL50PhNZA93OsqxSO1J1v4YG/HnPsPKmqob3K6+/59U9rn3DvdfQ4ZabFzATyFu0i4qu0dQX/o\nI2fZ8M91DN30H+FtfeKpUMhSXtXQad59udvd+wyMH5zVad79yAv6etbdK9xFTuVIOWxzg/7AZmfZ\n0CJnemXhNTBgtLf1SUyoPdHCpr0d0zA3VdTQ4Hb3AzJSKcrPaR/OmZKfTd/U3unuFe4ikTi2y5lD\nX/YS7N/oLBs4EfLGOV8rmJ3vDN+03fr01/fIJqlgyPLJ4fpOB2p3VR0HwO8zXDQ4s30a5tSC/hQM\n6JnuPqrhboyZCzwK+IHl1tqfdFn/z8BioBWoAm631u453Wsq3CXmVO9xzootX+1Mr6ytdL5pKlxq\nv85hnz288y+BrKG6bn0SqTnR7Fwvp6Jj7P54cxCACzJSO13+eMrwHPqknv+3lEUt3I0xfmAH8GWg\nElgPLLTWloVt8wVgnbX2hDHmbuAKa+2C072uwl1inrVwvApq9zpB33ZrC/7aSuc6OJ0YyBziBH1O\nflj4h/0ySM9R95+ggiHLjkP1nS5/vOtIR3c/YYjT3X996nAuyT+3s6sjDfdIBolmAOXW2l3uC68A\n5gPt4W6tfSNs+7XAzWdXrkgMMsaZI99vIAyb1v02LSehdp/7CyD8l8Be2L/J+Z9AsLnzc1Izu+/+\n234ZZA5R9x+nnADPYsKQLG5ho96uAAAJZklEQVSa6RykP3a82TnByg38FzZUckl+zjmHe6QiCfdh\nwN6wx5XAzNNsfwfw5/MpSiRupPSB3AudW3dCIbf7r/xs+Nfudcb5Txzt/Bzj6+j+O3X+Yf8D0DV1\n4saAjFTmTBjEnAmDAGgNhgj2wrHOqB7eNcbcDEwHLj/F+iXAEoCCgoJovrVIbPL5IHOQcxt+iu6/\n+QTUud1/TZdfAPs2dt/9p2Wdfuw/c4i+nDxGBfy+6Abvqd4ngm32Aflhj4e7yzoxxnwJ+D5wubW2\nqet6AGttCVACzpj7WVcrkohS+0LuWOfWnVAIjh/+bPdf43b/laVw8ljn5xgfZA7tCP7uxv916eSE\nFkm4rwfGGmNG4YR6MXBj+AbGmCLgcWCutfZw1KsUSWY+H2QOdm7DT3Ecrfn4Kcb+K2FfqTPVM9TS\n+TlpWZ892Nv2OCcf+g1W9x/HzviTs9a2GmPuAV7DmQr5hLV2qzHmh0CptXYV8B9AP+D37rzOCmvt\nNT1Yt4iES81w5ubnjet+fSjkfPHJqcb+K993vuownPE7UztPN/afntXzfzc5JzqJSUQcTQ2nGPt3\nfwnU7YNQa+fnpGWHDfl0/SXgjv37zn9ut3SI5lRIEUkGaf0gb7xz604o2H333/aLoGItNNZ0fo7x\nQ9awzuGf0+XM37TMnv+7JSGFu4hExucO02QNhfwZ3W/TVO+O/VdCbUXn7n/vWti6/7Pdf3p295d6\naJ/5M1jd/zlQuItI9KRlwsCLnFt3QkGoP3jqsf+K96CxtvNzfAF37L9r+BeEdf/9ev7vFmcU7iLS\ne3x+yB7m3E51LmRjnTv23+VSD7WVsGeNs84GOz8nPafzWb5du/9+g51ZR0lE4S4isSU9y7kNnND9\n+mArNBzs0vW7Y//Ve2D3u9DUtftP6b77bxv/zxqWcN2/wl1E4os/0BHOp9JYe+p5/3vehbr9n+3+\n+/T/7Jm+nbr/QXHV/SvcRSTxpGc7t0GF3a8PtkL9gc+O+ddWQvVu+PQdaK7v/Bxfijuk1N3QT76z\nLjWjx/9qkVK4i0jy8QecIZmc/FNv01jb+TIP4d3/p+9A/X6woc7P6TPgs1f5DO/+Mwb2WvevcBcR\n6U579z+x+/XBls92/21z/o/tgk/fguaGzs/xpzrj+1/8N7j4+h4tX+EuInIu/CmQU+DcumNtR/ff\n3vm7f2bk9nh5CncRkZ5gjHPd/T45MHhSr799/Bz6FRGRiCncRUQSkMJdRCQBKdxFRBKQwl1EJAEp\n3EVEEpDCXUQkASncRUQSkGffoWqMqQL2nOPTc4EjUSwnWlTX2VFdZy9Wa1NdZ+d86hphrc0700ae\nhfv5MMaURvIFsb1NdZ0d1XX2YrU21XV2eqMuDcuIiCQghbuISAKK13Av8bqAU1BdZ0d1nb1YrU11\nnZ0erysux9xFROT04rVzFxGR04i5cDfGzDXGbDfGlBtjvtvN+jRjzEp3/TpjzMiwdfe7y7cbY67s\n5br+2RhTZozZYoz5qzFmRNi6oDHmA/e2qpfrWmSMqQp7/8Vh624zxnzi3m7r5bp+HlbTDmNMTdi6\nntxfTxhjDhtjPjrFemOM+aVb9xZjzNSwdT2yvyKo6Sa3lg+NMe8ZY6aErdvtLv/AGFMarZrOorYr\njDG1YT+vH4StO+1noIfr+pewmj5yP1MD3HU9ss+MMfnGmDfcHNhqjPmnbrbpvc+XtTZmboAf2AmM\nBlKBzUBhl23+Efi1e78YWOneL3S3TwNGua/j78W6vgD0de/f3VaX+7jBw/21CPhVN88dAOxy/+zv\n3u/fW3V12f5/AE/09P5yX/vvganAR6dYfzXwZ8AAs4B1vbC/zlTTpW3vBVzVVpP7eDeQ6+H+ugL4\n0/l+BqJdV5dt5wF/6+l9BgwBprr3M4Ed3fx77LXPV6x17jOAcmvtLmttM7ACmN9lm/nA0+79F4A5\nxhjjLl9hrW2y1n4KlLuv1yt1WWvfsNaecB+uBYZH6b3Pq67TuBJ43Vp7zFpbDbwOzPWoroXA81F6\n79Oy1r4NHDvNJvOBZ6xjLZBjjBlCD+6vM9VkrX3PfU/ovc9W23ufaX+dyvl8NqNdV698vqy1B6y1\nG9379cA2YFiXzXrt8xVr4T4M2Bv2uJLP7pz2bay1rUAtcEGEz+3JusLdgfPbuU26MabUGLPWGHNt\nlGo6m7quc/8L+IIxpu3r3mNif7nDV6OAv4Ut7qn9FYlT1d6T++tsdP1sWeAvxpgNxpglHtQDMNsY\ns9kY82djTNu3ScfE/jLG9MUJyT+ELe7xfWac4eIiYF2XVb32+dJ3qEaZMeZmYDpwedjiEdbafcaY\n0cDfjDEfWmt39lJJfwSet9Y2GWPuwvlfzxd76b0jUQy8YK0Nhi3zcn/FLGPMF3DC/fNhiz/v7quB\nwOvGmI/drra3bMT5eTUYY64GXgTG9uL7n8k84F1rbXiX36P7zBjTD+eXyXestXXRet2zFWud+z4g\nP+zxcHdZt9sYYwJANnA0wuf2ZF0YY74EfB+4xlrb1LbcWrvP/XMX8CbOb/ReqctaezSsluXAtEif\n25N1hSmmy3+Ze3B/ReJUtffk/jojY8xknJ/ffGvt0bblYfvqMPD/iN5QZESstXXW2gb3/itAijEm\nF4/3V5jTfb6ivs+MMSk4wf47a+1/dbNJ732+on1Q4TwPSARwDiSMouMgzMQu23ybzgdU/9O9P5HO\nB1R3Eb0DqpHUVYRzAGlsl+X9gTT3fi7wCVE6sBRhXUPC7v8DsNZ2HMD51K2vv3t/QG/V5W53Ec7B\nLdMb+yvsPUZy6gOEX6XzAa/3e3p/RVBTAc4xpEu7LM8AMsPuvwfMjea+iqC2wW0/P5yQrHD3XUSf\ngZ6qy12fjTMun9Eb+8z9ez8D/OI02/Ta5yuqH4Io7aCrcY4y7wS+7y77IU43DJAO/N79sL8PjA57\n7vfd520HrurlulYDh4AP3Nsqd/mlwIfuh/tD4I5eruvfga3u+78BXBT23Nvd/VgOfLM363If/y/g\nJ12e19P763ngANCCM655B/At4FvuegMsdev+EJje0/srgpqWA9Vhn61Sd/lodz9tdn/G34/mvoqw\ntnvCPl9rCfsF1N1noLfqcrdZhDPJIvx5PbbPcIbLLLAl7Gd1tVefL52hKiKSgGJtzF1ERKJA4S4i\nkoAU7iIiCUjhLiKSgBTuIiIJSOEuIpKAFO4iIglI4S4ikoD+P+DYihtRIExwAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5-UamSb8G3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Create the encoder model from the tensors we previously declared.\n",
        "encoder_model = Model(encoder_inputs, [encoder_out, state_h, state_c])\n",
        "\n",
        "# Generate a new set of tensors for our new inference decoder. Note that we are using new tensors, \n",
        "# this does not preclude using the same underlying layers that we trained on. (e.g. weights/biases).\n",
        "\n",
        "inf_decoder_inputs = Input(shape=(None,), name=\"inf_decoder_inputs\")\n",
        "# We'll need to force feed the two state variables into the decoder each step.\n",
        "state_input_h = Input(shape=(units*2,), name=\"state_input_h\")\n",
        "state_input_c = Input(shape=(units*2,), name=\"state_input_c\")\n",
        "decoder_res, decoder_h, decoder_c = decoder_lstm(\n",
        "    decoder_emb(inf_decoder_inputs), \n",
        "    initial_state=[state_input_h, state_input_c])\n",
        "inf_decoder_out = decoder_d2(decoder_d1(decoder_res))\n",
        "inf_model = Model(inputs=[inf_decoder_inputs, state_input_h, state_input_c], \n",
        "                  outputs=[inf_decoder_out, decoder_h, decoder_c])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjvkGbFG8Lqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converts the given sentence (just a string) into a vector of word IDs\n",
        "# Output is 1-D: [timesteps/words]\n",
        "\n",
        "def sentence_to_vector(sentence, lang):\n",
        "\n",
        "    pre = sentence\n",
        "    vec = np.zeros(len_input)\n",
        "    sentence_list = [lang.word2idx[s] for s in pre.split(' ')]\n",
        "    for i,w in enumerate(sentence_list):\n",
        "        vec[i] = w\n",
        "    return vec\n",
        "\n",
        "# Given an input string, an encoder model (infenc_model) and a decoder model (infmodel),\n",
        "def translate(input_sentence, infenc_model, infmodel):\n",
        "    sv = sentence_to_vector(input_sentence, input_lang)\n",
        "    sv = sv.reshape(1,len(sv))\n",
        "    [emb_out, sh, sc] = infenc_model.predict(x=sv)\n",
        "    \n",
        "    i = 0\n",
        "    start_vec = target_lang.word2idx[\"<start>\"]\n",
        "    stop_vec = target_lang.word2idx[\"<end>\"]\n",
        "    \n",
        "    cur_vec = np.zeros((1,1))\n",
        "    cur_vec[0,0] = start_vec\n",
        "    cur_word = \"<start>\"\n",
        "    output_sentence = \"\"\n",
        "\n",
        "    while cur_word != \"<end>\" and i < (len_target-1):\n",
        "        i += 1\n",
        "        if cur_word != \"<start>\":\n",
        "            output_sentence = output_sentence + \" \" + cur_word\n",
        "        x_in = [cur_vec, sh, sc]\n",
        "        [nvec, sh, sc] = infmodel.predict(x=x_in)\n",
        "        cur_vec[0,0] = np.argmax(nvec[0,0])\n",
        "        cur_word = target_lang.idx2word[np.argmax(nvec[0,0])]\n",
        "    return output_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQuHwOof8QjF",
        "colab_type": "code",
        "outputId": "cc7f07fe-e9f7-45b3-cae1-998d224a844b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "#Note that only words that we've trained the model on will be available, otherwise you'll get an error.\n",
        "\n",
        "\n",
        "test = [\n",
        "    'hi there',\n",
        "    'hell',\n",
        "    'presentation please fin',\n",
        "    'resignation please find at',\n",
        "    'resignation please ',\n",
        "    'have a nice we',\n",
        "    'let me ',\n",
        "    'promotion congrats ',\n",
        "    'christmas Merry ',\n",
        "    'please rev',\n",
        "    'please ca',\n",
        "    'thanks fo',\n",
        "    'Let me kno',\n",
        "    'Let me know if y',\n",
        "    'this soun',\n",
        "    'is this call going t'\n",
        "]\n",
        "  \n",
        "\n",
        "import pandas as pd\n",
        "output = []  \n",
        "for t in test:  \n",
        "  output.append({\"Input seq\":t.lower(), \"Pred. Seq\":translate(t.lower(), encoder_model, inf_model)})\n",
        "\n",
        "results_df = pd.DataFrame.from_dict(output) \n",
        "results_df.head(len(test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input seq</th>\n",
              "      <th>Pred. Seq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi there</td>\n",
              "      <td>maryhain.nsf  please see attached.    el0095.1   el0153.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hell</td>\n",
              "      <td>e farmerd xfilename: dfarmer.nsf  (see attached file: hpl0912.xls)    hpl0912.xls</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>presentation please fin</td>\n",
              "      <td>e dgiron (nonprivileged).pst        linziboat42(2).jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>resignation please find at</td>\n",
              "      <td>carol's changes so we can book our flights to kansas.  d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>resignation please</td>\n",
              "      <td>maryhain.nsf  i would like to go this questions of you  soon.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>have a nice we</td>\n",
              "      <td>me a candidate.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>let me</td>\n",
              "      <td>know if you need anything else.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>promotion congrats</td>\n",
              "      <td>a saint.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>christmas merry</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>please rev</td>\n",
              "      <td>e mhaedic.nsf  please see attached:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>please ca</td>\n",
              "      <td>l you please send me the chilean capacity spreadsheet you'd put together?  thanks.  karen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>thanks fo</td>\n",
              "      <td>be a  callin number for this?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>let me kno</td>\n",
              "      <td>e me anything else or if you have any questions.  thanks    generators2.wpd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>let me know if y</td>\n",
              "      <td>t you have any questions.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>this soun</td>\n",
              "      <td>e be out of the office until monday 27th and 28th to ces at face morning!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>is this call going t</td>\n",
              "      <td>o see cv from you</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Input seq                                                                                   Pred. Seq\n",
              "0   hi there                      maryhain.nsf  please see attached.    el0095.1   el0153.1                               \n",
              "1   hell                         e farmerd xfilename: dfarmer.nsf  (see attached file: hpl0912.xls)    hpl0912.xls        \n",
              "2   presentation please fin      e dgiron (nonprivileged).pst        linziboat42(2).jpg                                   \n",
              "3   resignation please find at    carol's changes so we can book our flights to kansas.  d                                \n",
              "4   resignation please            maryhain.nsf  i would like to go this questions of you  soon.                           \n",
              "5   have a nice we                me a candidate.                                                                         \n",
              "6   let me                        know if you need anything else.                                                         \n",
              "7   promotion congrats            a saint.                                                                                \n",
              "8   christmas merry                                                                                                       \n",
              "9   please rev                   e mhaedic.nsf  please see attached:                                                      \n",
              "10  please ca                    l you please send me the chilean capacity spreadsheet you'd put together?  thanks.  karen\n",
              "11  thanks fo                     be a  callin number for this?                                                           \n",
              "12  let me kno                   e me anything else or if you have any questions.  thanks    generators2.wpd              \n",
              "13  let me know if y             t you have any questions.                                                                \n",
              "14  this soun                    e be out of the office until monday 27th and 28th to ces at face morning!                \n",
              "15  is this call going t         o see cv from you                                                                        "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_10pgS38Udd",
        "colab_type": "code",
        "outputId": "0195c465-0781-414d-ec9a-3664cdf6f1c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# This is to save the model for the web app to use for generation\n",
        "from keras.models import model_from_json\n",
        "from keras.models import load_model\n",
        "\n",
        "# serialize model to JSON\n",
        "#  the keras model which is trained is defined as 'model' in this example\n",
        "model_json = inf_model.to_json()\n",
        "\n",
        "\n",
        "with open(\"./sample_data/model_num.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# serialize weights to HDF5\n",
        "inf_model.save_weights(\"./sample_data/model_num.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTdUt__J9UFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}