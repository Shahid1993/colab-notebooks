{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conditional_gen.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahid1993/colab-notebooks/blob/master/conditional_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_42PJRcysYFA",
        "colab_type": "text"
      },
      "source": [
        "# [Building Gmail style smart compose with a char ngram language model](https://towardsdatascience.com/gmail-style-smart-compose-using-char-n-gram-language-models-a73c09550447)\n",
        "\n",
        "### Let’s build a simple and powerful language model from scratch and use it for text generation.\n",
        "\n",
        "If you are a Gmail user, by now you would have experienced the *smart compose* feature. It’s the new automatic sentence completion feature that takes email productivity to an exciting new level. It was released in Google I/O 2018. \n",
        "\n",
        "## Smart compose is smarter than you think\n",
        "\n",
        "**Whatsapp** offers a predictive text and **Google search** auto completes our queries with trending searches as you type in. Overall both offer a simple **model based prefix search**, i.e the text typed in by the user is used as the prefix to predict the next word the user might want to type (in Whatsapp’s case) or user’s search intent (in the Google search case). **Smart compose** is a nifty extension of predictive text and auto complete, but there is more to it.\n",
        "\n",
        "### Whatsapp Predictive Text\n",
        "Whatsapp predicts the next possible word and presents you with the top 3 possibilities. While it is model based, it only predicts the next word (unigram) or at most the next word pair (a bigram), but nothing further.\n",
        "\n",
        "![](https://miro.medium.com/max/1806/1*yMsFXA67-B8JOn11bOBM3g.png)\n",
        "\n",
        "### Google autocomplete\n",
        "The query autocomplete (shown below) is also a model based solution that factors in the search phrase typed in so far and runs a prefix search on the trending searches.\n",
        "\n",
        "![](https://miro.medium.com/max/654/1*_pJzicw2R8Ki6Y-dYdT-jQ.gif)\n",
        "\n",
        "### Smart compose\n",
        "Word level predictive texts are great, but they are a great fit only where the user inputs come in short spurts. But with emails, the user is going to type in a lot of text in one go across multiple emails. So lesser the user needs to type, the greater the user experience and productivity. Also, In emails if you look close, we end up repeating lot of sentences, from greetings to basic pleasantries to closure notes.\n",
        "\n",
        "Smart compose not only uses the current text, it uses the subject and the previous message (if the user is replying) to complete the sentence for you.\n",
        "\n",
        "### Motivation\n",
        "\n",
        "NMT (Neural Machine Translation) has sort of become the canonical use case for explaining sequence to sequence models (Seq2Seq models). While there is nothing wrong in that, IMHO NMT doesn’t do justice to all the magic the Seq2Seq paradigm can offer. Besides MT (Machine Translation) is not a well solved problem (at least as of this writing). But look at smart email response (Kannan et al., 2016) and smart compose (gmail), they are practical solutions that work really well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FkSKN8VwHFT",
        "colab_type": "text"
      },
      "source": [
        "## Language models, RNNs and Seq2Seq Modelling\n",
        "\n",
        "### Language models: Intuition\n",
        "\n",
        "The modern incarnation of a Language Model (LM) is a critical milestone in the progression of NLP as a field . So, let’s start by understanding the intuition behind a LM.\n",
        "\n",
        "![](https://miro.medium.com/max/1024/1*yxbmLf7Rv9z-bRGThgSaVw.png)\n",
        "\n",
        "LMs learn a representation of a text corpus similar to a word embedding but better one. Now, What do I mean by that ? Simply put, the goal of a LM is to break up a text corpus and assign probabilities to text sequences, typically one word at a time.(but there are other variants).\n",
        "\n",
        "So, how does this work ? For a text sequence _“The dog barked at the stranger”_ in our corpus, a word based LM estimates the probability of P(_“The dog barked at the stranger”_) one word at a time using the chain rule of probability. It starts with the probability of the first word(“The”) and continues with, the probability of second word(“dog”) given the first word(“The”) and then goes on to the probability of the third word given the first & second word and so on. Mathematically speaking the LM estimates the following,\n",
        "\n",
        "![](https://miro.medium.com/max/1338/1*hjhcaY4Rir_kQv5ZNeJIMA.png)\n",
        "\n",
        "Concretely, a LM estimates the following, where n is the number of words.\n",
        "\n",
        "![](https://miro.medium.com/max/1296/1*EbyWjo-Nvmbnbv2-a4opRg.png)\n",
        "\n",
        "LMs have many different use cases. One of it is, A LM can tell how probable a text sequence is for a given corpus. For instance, a text sequence **P(“A dog flew upside down without wings)** will yield a very low probability unless the text corpus came out of some fiction novel. But this use case is less interesting to us. What is more interesting is, LMs are a natural fit for sequence generation (in this case text generation).\n",
        "\n",
        "1. We can ask a LM to generate a random sequence of arbitrary length with or without **prefix** (also referred as **seed** or **prompt** sometimes). The prefix or prompt can be anything, a word or another sequence of arbitrary length. For instance, we can prompt a LM with a word to generate a random sentence or we can prompt a LM with a sentence to generate a sentence or a paragraph. _The special case of generating an arbitrary length sequence given a arbitrary length sequence as input is called **conditioned generation**, as the output is conditioned on the input. That is in fact why this paradigm is called Seq2Seq modelling._ Machine Translation is the canonical example of conditioned generation because it is easy to drive the point to the readers. So, shown below is a layout of a classical Seq2Seq model where _**x1,x2…xn**_ being the input sequence and _**y1,y2..ym**_ being the output sequence. (\\<start> and \\<end> are teacher forcing delimiters)\n",
        "\n",
        "![Layout of an RNN based Conditioned Generator](https://miro.medium.com/max/2236/1*b0ycohanqi_2jYyRMCuh5A.png)\n",
        "\n",
        "2. So if you connect the dots, Gmail smart compose is nothing but a **“conditioned generation”** with the _input sequence = current email message + the subject line + the previous email message (if you are replying) and the output sequence = the predicted sentence completions._ (I encourage you to pause here and try composing a message in gmail to see how conditioned generation works). The below diagram shows one possible smart compose model architecture\n",
        "\n",
        "![Conditioned generation in Smart Compose](https://miro.medium.com/max/2462/1*toRTIkFb9i_MYiIykpqWeA.png)\n",
        "\n",
        "Ok, what does this all has to do with RNNs and Encoder-Decoder architecture, how does this all connect ? Let’s look at them one at a time\n",
        "\n",
        "1.   **How are LMs and RNNs related ?** LMs aren’t new. People have been using a Markov models for learning a LM in the past. But it wasn’t the best choice since it had many disadvantages, the details are out of scope for this post. So, long story short RNNs emerged as the goto architecture to do sequence modelling and hence to do LM, as they come with an array of promises to overcome the shortcomings of Markov models. Especially the fact that RNNs can defy Markov limitation and factor in long range dependencies.\n",
        "\n",
        " 2.   **How RNNs and Conditioned Generation are related?** The below figure shows couple of different Seq2Seq modelling flavours RNNs offer. If you compare the conditioned generator layout above with these images it will be obvious to you, that the many to many **(n:m)** flavour i.e where input sequence length is _not equal_ to output sequence length is exactly same as a conditioned generator. _( For the context of this post we will be considering a RNN based conditioned generators but there are more advanced architectures like **Transformers** to implement conditioned generators)_\n",
        " \n",
        " ![](https://miro.medium.com/max/555/1*kbml6zYermJubzcsbfIYnA.png)\n",
        " \n",
        "3. **How conditioned generators and encoder-decoders are related ?** Conditioned generator is just another name for the Encoder-Decoder architecture, whereas generators, conditioned generators are the terms coming from NLP literature. In fact the term “conditioned generator” explains **“what”** the architecture does and the term **“Encoder-Decoder”** simply names the components in the architecture.\n",
        "\n",
        "Now that we have tied everything together nicely. Let’s grok about how we can implement one such conditioned generator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv53pjKS078j",
        "colab_type": "text"
      },
      "source": [
        "## The Experiment\n",
        "\n",
        "### Synthetic dataset creation\n",
        "\n",
        "I used the [Enron email dataset](https://www.cs.cmu.edu/~enron/) as a source to extract and prepare few email messages for this experiment.\n",
        "\n",
        "### Implementation details\n",
        "\n",
        "Sample of some short messages used in this experiment.\n",
        "\n",
        "![Sample of some short messages used in this experiment.](https://miro.medium.com/max/614/1*3hDYqQxI5ujFs_6ZF-34QQ.png)\n",
        "\n",
        "In gmail sentence completion, you can see the predictions don’t actually wait for you to finish an entire word. So we might need a LM much more granular than the ones at word level, **Hence I chose to build at a char ngram level**. One way to accomplish that is to prepare the dataset as shown below:\n",
        "\n",
        "![](https://miro.medium.com/max/372/1*brangiq3muqzubUee70YXQ.png)\n",
        "\n",
        "Also,  subject text is added (prefixed) to the email body text as a part of data preparation, so a single training record = subject text (if one available) + message text\n",
        "\n",
        "_Again this is purely for the experimental purposes, because with a large corpus this style of data preparation can be very memory intensive as one text sequence turns into multiple sequences with char ngram prefixes._\n",
        "\n",
        "Now how does a char ngram level LM change our Encoder-Decoder architecture ? It doesn’t, architecture would be the same, but how it trains changes (shown below).\n",
        "\n",
        "![Char n-gram conditioning for generation (shown in red)](https://miro.medium.com/max/2464/1*N6zO1d4ccY4b5goeSLJa3Q.png)\n",
        "\n",
        "\n",
        "**Brass tacks:** The architecture choices that worked well were a **BiLSTM Encoder and a LSTM Decoder**. For simplicity I wrote this in Python, Keras.\n",
        "\n",
        "\n",
        "## Future work and possible extensions\n",
        "\n",
        " -   Understand the Perplexity of the above LM.\n",
        " -   Add Attention mechanism.\n",
        " -   Replace LSTMs with Transformers.\n",
        " -   Try longer messages and longer prompts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rqIkznPzTz0",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing Enron Email Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzYmnnl-eGVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To mount Google Drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-iD8N7-F596",
        "colab_type": "code",
        "outputId": "e69420c8-1079-4046-e811-6eedc4f818f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!unzip ./sample_data/enron-email-dataset.zip -d ./sample_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./sample_data/enron-email-dataset.zip\n",
            "  inflating: ./sample_data/emails.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3eWjasEzZRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNsSBHu-zlsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"./sample_data/emails.csv\")\n",
        "pd.set_option('display.max_colwidth',-1)\n",
        "new = data[\"message\"].str.split(\"\\n\", n = 15, expand = True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnugzK2gzm4F",
        "colab_type": "code",
        "outputId": "5803b162-0ad0-4e3c-92ce-a09c15e21214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "new.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.evans@thyme&gt;</td>\n",
              "      <td>Date: Mon, 14 May 2001 16:39:00 -0700 (PDT)</td>\n",
              "      <td>From: phillip.allen@enron.com</td>\n",
              "      <td>To: tim.belden@enron.com</td>\n",
              "      <td>Subject:</td>\n",
              "      <td>Mime-Version: 1.0</td>\n",
              "      <td>Content-Type: text/plain; charset=us-ascii</td>\n",
              "      <td>Content-Transfer-Encoding: 7bit</td>\n",
              "      <td>X-From: Phillip K Allen</td>\n",
              "      <td>X-To: Tim Belden &lt;Tim Belden/Enron@EnronXGate&gt;</td>\n",
              "      <td>X-cc:</td>\n",
              "      <td>X-bcc:</td>\n",
              "      <td>X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail</td>\n",
              "      <td>X-Origin: Allen-P</td>\n",
              "      <td>X-FileName: pallen (Non-Privileged).pst</td>\n",
              "      <td>\\nHere is our forecast\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.evans@thyme&gt;</td>\n",
              "      <td>Date: Fri, 4 May 2001 13:51:00 -0700 (PDT)</td>\n",
              "      <td>From: phillip.allen@enron.com</td>\n",
              "      <td>To: john.lavorato@enron.com</td>\n",
              "      <td>Subject: Re:</td>\n",
              "      <td>Mime-Version: 1.0</td>\n",
              "      <td>Content-Type: text/plain; charset=us-ascii</td>\n",
              "      <td>Content-Transfer-Encoding: 7bit</td>\n",
              "      <td>X-From: Phillip K Allen</td>\n",
              "      <td>X-To: John J Lavorato &lt;John J Lavorato/ENRON@enronXgate@ENRON&gt;</td>\n",
              "      <td>X-cc:</td>\n",
              "      <td>X-bcc:</td>\n",
              "      <td>X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail</td>\n",
              "      <td>X-Origin: Allen-P</td>\n",
              "      <td>X-FileName: pallen (Non-Privileged).pst</td>\n",
              "      <td>\\nTraveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.\\n\\nAs far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.  \\n\\nMy suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                           0  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         15\n",
              "0  Message-ID: <18782981.1075855378110.JavaMail.evans@thyme>  ...  \\nHere is our forecast\\n\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
              "1  Message-ID: <15464986.1075855378456.JavaMail.evans@thyme>  ...  \\nTraveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.\\n\\nAs far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.  \\n\\nMy suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time.\\n\n",
              "\n",
              "[2 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEC0CgIL6Acj",
        "colab_type": "code",
        "outputId": "8f1f4a90-f617-42db-c8d3-2eeab5829c54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "data.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>allen-p/_sent_mail/1.</td>\n",
              "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.evans@thyme&gt;\\nDate: Mon, 14 May 2001 16:39:00 -0700 (PDT)\\nFrom: phillip.allen@enron.com\\nTo: tim.belden@enron.com\\nSubject: \\nMime-Version: 1.0\\nContent-Type: text/plain; charset=us-ascii\\nContent-Transfer-Encoding: 7bit\\nX-From: Phillip K Allen\\nX-To: Tim Belden &lt;Tim Belden/Enron@EnronXGate&gt;\\nX-cc: \\nX-bcc: \\nX-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\\nX-Origin: Allen-P\\nX-FileName: pallen (Non-Privileged).pst\\n\\nHere is our forecast\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>allen-p/_sent_mail/10.</td>\n",
              "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.evans@thyme&gt;\\nDate: Fri, 4 May 2001 13:51:00 -0700 (PDT)\\nFrom: phillip.allen@enron.com\\nTo: john.lavorato@enron.com\\nSubject: Re:\\nMime-Version: 1.0\\nContent-Type: text/plain; charset=us-ascii\\nContent-Transfer-Encoding: 7bit\\nX-From: Phillip K Allen\\nX-To: John J Lavorato &lt;John J Lavorato/ENRON@enronXgate@ENRON&gt;\\nX-cc: \\nX-bcc: \\nX-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\\nX-Origin: Allen-P\\nX-FileName: pallen (Non-Privileged).pst\\n\\nTraveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.\\n\\nAs far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.  \\n\\nMy suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     file                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            message\n",
              "0  allen-p/_sent_mail/1.   Message-ID: <18782981.1075855378110.JavaMail.evans@thyme>\\nDate: Mon, 14 May 2001 16:39:00 -0700 (PDT)\\nFrom: phillip.allen@enron.com\\nTo: tim.belden@enron.com\\nSubject: \\nMime-Version: 1.0\\nContent-Type: text/plain; charset=us-ascii\\nContent-Transfer-Encoding: 7bit\\nX-From: Phillip K Allen\\nX-To: Tim Belden <Tim Belden/Enron@EnronXGate>\\nX-cc: \\nX-bcc: \\nX-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\\nX-Origin: Allen-P\\nX-FileName: pallen (Non-Privileged).pst\\n\\nHere is our forecast\\n\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
              "1  allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.evans@thyme>\\nDate: Fri, 4 May 2001 13:51:00 -0700 (PDT)\\nFrom: phillip.allen@enron.com\\nTo: john.lavorato@enron.com\\nSubject: Re:\\nMime-Version: 1.0\\nContent-Type: text/plain; charset=us-ascii\\nContent-Transfer-Encoding: 7bit\\nX-From: Phillip K Allen\\nX-To: John J Lavorato <John J Lavorato/ENRON@enronXgate@ENRON>\\nX-cc: \\nX-bcc: \\nX-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\\nX-Origin: Allen-P\\nX-FileName: pallen (Non-Privileged).pst\\n\\nTraveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.\\n\\nAs far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.  \\n\\nMy suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time.\\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYNW0xkU6Ie2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"from\"] = new[2]\n",
        "data[\"fromn\"] = new[8]\n",
        "data[\"to\"] = new[3]\n",
        "data[\"ton\"] = new[9]\n",
        "data[\"subject\"] = new[4]\n",
        "data[\"msg\"] = new[15]\n",
        "data.drop(columns =[\"message\"], inplace = True) \n",
        "data.drop(columns =[\"file\"], inplace = True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd5yfsGn6Nyv",
        "colab_type": "code",
        "outputId": "2c694b31-c6e6-498a-f380-d1a2cb28a2ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>fromn</th>\n",
              "      <th>to</th>\n",
              "      <th>ton</th>\n",
              "      <th>subject</th>\n",
              "      <th>msg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: phillip.allen@enron.com</td>\n",
              "      <td>X-From: Phillip K Allen</td>\n",
              "      <td>To: tim.belden@enron.com</td>\n",
              "      <td>X-To: Tim Belden &lt;Tim Belden/Enron@EnronXGate&gt;</td>\n",
              "      <td>Subject:</td>\n",
              "      <td>\\nHere is our forecast\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: phillip.allen@enron.com</td>\n",
              "      <td>X-From: Phillip K Allen</td>\n",
              "      <td>To: john.lavorato@enron.com</td>\n",
              "      <td>X-To: John J Lavorato &lt;John J Lavorato/ENRON@enronXgate@ENRON&gt;</td>\n",
              "      <td>Subject: Re:</td>\n",
              "      <td>\\nTraveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.\\n\\nAs far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.  \\n\\nMy suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            from  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        msg\n",
              "0  From: phillip.allen@enron.com  ...  \\nHere is our forecast\\n\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
              "1  From: phillip.allen@enron.com  ...  \\nTraveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.\\n\\nAs far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.  \\n\\nMy suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time.\\n\n",
              "\n",
              "[2 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbmQc_Ox6Pg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['from'] = data[\"from\"].apply(lambda val: val.replace(\"From:\",''))\n",
        "data['fromn'] = data[\"fromn\"].apply(lambda val: val.replace(\"X-From:\",''))\n",
        "data['to'] = data[\"to\"].apply(lambda val: val.replace(\"To:\",''))\n",
        "data['ton'] = data[\"ton\"].apply(lambda val: val.replace(\"X-To:\",''))\n",
        "data['subject'] = data[\"subject\"].apply(lambda val: val.replace(\"Subject:\",''))\n",
        "data['msg'] = data[\"msg\"].apply(lambda val: val.replace(\"\\n\",' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIqBN7PL6U0v",
        "colab_type": "code",
        "outputId": "0a5e425a-87ab-4e1a-db3f-f00e3a96d882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>fromn</th>\n",
              "      <th>to</th>\n",
              "      <th>ton</th>\n",
              "      <th>subject</th>\n",
              "      <th>msg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>phillip.allen@enron.com</td>\n",
              "      <td>Phillip K Allen</td>\n",
              "      <td>tim.belden@enron.com</td>\n",
              "      <td>Tim Belden &lt;Tim Belden/Enron@EnronXGate&gt;</td>\n",
              "      <td></td>\n",
              "      <td>Here is our forecast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>phillip.allen@enron.com</td>\n",
              "      <td>Phillip K Allen</td>\n",
              "      <td>john.lavorato@enron.com</td>\n",
              "      <td>John J Lavorato &lt;John J Lavorato/ENRON@enronXgate@ENRON&gt;</td>\n",
              "      <td>Re:</td>\n",
              "      <td>Traveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.  As far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.    My suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       from  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  msg\n",
              "0   phillip.allen@enron.com  ...   Here is our forecast                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
              "1   phillip.allen@enron.com  ...   Traveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.  As far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.    My suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time. \n",
              "\n",
              "[2 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKZVxfIo6XEl",
        "colab_type": "code",
        "outputId": "08cc5972-213c-425b-f67e-543a3d3b7410",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "# Lets look only at emails with 100 words or less and that are Non-replies\n",
        "data[(data['msg'].str.len() <100) & ~(data['subject'].str.contains('Re:'))].sample(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>fromn</th>\n",
              "      <th>to</th>\n",
              "      <th>ton</th>\n",
              "      <th>subject</th>\n",
              "      <th>msg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>357346</th>\n",
              "      <td>joe.parks@enron.com</td>\n",
              "      <td>Parks, Joe &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=JPARKS&gt;</td>\n",
              "      <td>frank.hayden@enron.com</td>\n",
              "      <td>Hayden, Frank &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Fhayden&gt;</td>\n",
              "      <td></td>\n",
              "      <td>WHEN WILL WE KNOW HOW THE WINNER IS?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143016</th>\n",
              "      <td>mattias.palm@paconsulting.com</td>\n",
              "      <td>X-To:</td>\n",
              "      <td>Subject: Salmon anyone?</td>\n",
              "      <td>X-cc:</td>\n",
              "      <td>Mime-Version: 1.0</td>\n",
              "      <td>&lt;&lt;laxen.asf&gt;&gt;  /mattias    - laxen.asf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495546</th>\n",
              "      <td>pahlbrand@indy.rr.com</td>\n",
              "      <td>Content-Transfer-Encoding: 7bit</td>\n",
              "      <td>watson@enron.com, kwatson@enron.com, reed@enron.com, reedrev@voyager.net,</td>\n",
              "      <td>X-From: Phil Ahlbrand &lt;pahlbrand@indy.rr.com&gt;</td>\n",
              "      <td>\\treed@enron.com, revdavidreed@aol.com</td>\n",
              "      <td>X-FileName: KWATSON (Non-Privileged).pst  My new e-mail address:  pahlbrand@indy.rr.com .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505064</th>\n",
              "      <td>zionette.vincent@enron.com</td>\n",
              "      <td>Zionette Vincent</td>\n",
              "      <td>Subject: Reschedule - EB3270 - Staff Mtg. (Lunch Provided) (4 June 11:30 AM</td>\n",
              "      <td></td>\n",
              "      <td>CDT)</td>\n",
              "      <td>Brandee w/conf. 5-4013  11:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16684</th>\n",
              "      <td>eric.bass@enron.com</td>\n",
              "      <td>Eric Bass</td>\n",
              "      <td>jason.bass2@compaq.com</td>\n",
              "      <td>Jason.Bass2@COMPAQ.com</td>\n",
              "      <td>computer</td>\n",
              "      <td>option 1 is an extra $600  option 2 is an extra $1300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  from  ...                                                                                        msg\n",
              "357346   joe.parks@enron.com            ...   WHEN WILL WE KNOW HOW THE WINNER IS?                                                    \n",
              "143016   mattias.palm@paconsulting.com  ...   <<laxen.asf>>  /mattias    - laxen.asf                                                  \n",
              "495546   pahlbrand@indy.rr.com          ...  X-FileName: KWATSON (Non-Privileged).pst  My new e-mail address:  pahlbrand@indy.rr.com .\n",
              "505064   zionette.vincent@enron.com     ...   Brandee w/conf. 5-4013  11:15                                                           \n",
              "16684    eric.bass@enron.com            ...   option 1 is an extra $600  option 2 is an extra $1300                                   \n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pic0sVy6b-5",
        "colab_type": "code",
        "outputId": "cf5c001e-5a6d-4cf2-b008-745237d044b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "data.head()['msg']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     Here is our forecast                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
              "1     Traveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.  As far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.    My suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time. \n",
              "2     test successful.  way to go!!!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
              "3     Randy,   Can you send me a schedule of the salary and level of everyone in the  scheduling group.  Plus your thoughts on any changes that need to be made.   (Patti S for example)  Phillip                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
              "4     Let's shoot for Tuesday at 11:45.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
              "Name: msg, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwE8cjrn7JOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#corpus = [msg for msg in data[(data['msg'].str.len() <100) & ~(data['subject'].str.contains('Re:'))]['msg']]\n",
        "\n",
        "file = open(\"./sample_data/smart_compose.txt\", 'r')\n",
        "corpus = [line for line in file]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWfxURtp7KLp",
        "colab_type": "code",
        "outputId": "5aed3c16-5e77-4b51-8800-a44034a063a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "corpus[60:69]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A black dog and a white dog with brown spots are staring at each other in the street .\\n',\n",
              " 'A black dog and a tri-colored dog playing with each other on the road .\\n',\n",
              " 'Two dogs of different breeds looking at each other on the road .\\n',\n",
              " 'Two dogs on pavement moving toward each other .\\n',\n",
              " 'A black dog and a spotted dog are fighting\\n',\n",
              " 'A man with reflective safety clothes and ear protection drives a John Deere tractor on a road .\\n',\n",
              " 'John Deere tractors cruises down a street , while the driver wears easy to see clothing .\\n',\n",
              " 'A man in a neon green and orange uniform is driving on a green tractor .\\n',\n",
              " 'A man in a tractor wearing headphones driving down a paved street .\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCxtqjoZ7OMQ",
        "colab_type": "code",
        "outputId": "7cec85c7-d940-4f94-89f2-449dad2d5a93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(corpus)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "158915"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bml4t8rhpYNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Taking only as subset of corpus, since it takes lot of time for training\n",
        "#corpus = corpus[0:10000]\n",
        "\n",
        "corpus = corpus[0:2500]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yux4w690psbF",
        "colab_type": "code",
        "outputId": "676fa243-95f5-42fa-e06b-5f7e7484e426",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(corpus)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0ZsBrqU7TwL",
        "colab_type": "code",
        "outputId": "66c2c445-2836-4bf1-8498-d9db140ec41b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Start by importing all the things we'll need.\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, CuDNNLSTM, Flatten, TimeDistributed, Dropout, LSTMCell, RNN, Bidirectional, Concatenate, Layer\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.python.keras.utils import tf_utils\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, os \n",
        "tf.__version__"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_RkYugZ7cig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_special_chars(text, punct):\n",
        "    for p in punct:\n",
        "        text = text.replace(p, '')\n",
        "    return text\n",
        "\n",
        "      \n",
        "def preprocess(data):\n",
        "    output = []\n",
        "    punct = '#$%&*+-/<=>@[\\\\]^_`{|}~\\t\\n'\n",
        "    for line in data:\n",
        "         pline= clean_special_chars(line.lower(), punct)\n",
        "         output.append(pline)\n",
        "    return output  \n",
        "\n",
        "\n",
        "def generate_dataset():\n",
        "  \n",
        "    processed_corpus = preprocess(corpus)    \n",
        "    output = []\n",
        "    for line in processed_corpus:\n",
        "        token_list = line\n",
        "        for i in range(1, len(token_list)):\n",
        "            data = []\n",
        "            x_ngram = '<start> '+ token_list[:i+1] + ' <end>'\n",
        "            y_ngram = '<start> '+ token_list[i+1:] + ' <end>'\n",
        "            data.append(x_ngram)\n",
        "            data.append(y_ngram)\n",
        "            output.append(data)\n",
        "    print(\"Dataset prepared with prefix and suffixes for teacher forcing technique\")\n",
        "    dummy_df = pd.DataFrame(output, columns=['input','output'])\n",
        "    return output, dummy_df            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xrqss6-7kGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LanguageIndex():\n",
        "    def __init__(self, lang):\n",
        "        self.lang = lang\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "    def create_index(self):\n",
        "        for phrase in self.lang:\n",
        "            self.vocab.update(phrase.split(' '))\n",
        "        self.vocab = sorted(self.vocab)\n",
        "        self.word2idx[\"<pad>\"] = 0\n",
        "        self.idx2word[0] = \"<pad>\"\n",
        "        for i,word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = i + 1\n",
        "            self.idx2word[i+1] = word\n",
        "\n",
        "def max_length(t):\n",
        "    return max(len(i) for i in t)\n",
        "\n",
        "def load_dataset():\n",
        "    pairs,df = generate_dataset()\n",
        "    out_lang = LanguageIndex(sp for en, sp in pairs)\n",
        "    in_lang = LanguageIndex(en for en, sp in pairs)\n",
        "    input_data = [[in_lang.word2idx[s] for s in en.split(' ')] for en, sp in pairs]\n",
        "    output_data = [[out_lang.word2idx[s] for s in sp.split(' ')] for en, sp in pairs]\n",
        "\n",
        "    max_length_in, max_length_out = max_length(input_data), max_length(output_data)\n",
        "    input_data = tf.keras.preprocessing.sequence.pad_sequences(input_data, maxlen=max_length_in, padding=\"post\")\n",
        "    output_data = tf.keras.preprocessing.sequence.pad_sequences(output_data, maxlen=max_length_out, padding=\"post\")\n",
        "    return input_data, output_data, in_lang, out_lang, max_length_in, max_length_out, df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBUsKoAB7mIX",
        "colab_type": "code",
        "outputId": "cf7df5b7-a15b-430d-c093-d3d0668d2285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input_data, teacher_data, input_lang, target_lang, len_input, len_target, df = load_dataset()\n",
        "\n",
        "\n",
        "target_data = [[teacher_data[n][i+1] for i in range(len(teacher_data[n])-1)] for n in range(len(teacher_data))]\n",
        "target_data = tf.keras.preprocessing.sequence.pad_sequences(target_data, maxlen=len_target, padding=\"post\")\n",
        "target_data = target_data.reshape((target_data.shape[0], target_data.shape[1], 1))\n",
        "\n",
        "# Shuffle all of the data in unison. This training set has the longest (e.g. most complicated) data at the end,\n",
        "# so a simple Keras validation split will be problematic if not shuffled.\n",
        "\n",
        "p = np.random.permutation(len(input_data))\n",
        "input_data = input_data[p]\n",
        "teacher_data = teacher_data[p]\n",
        "target_data = target_data[p]"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset prepared with prefix and suffixes for teacher forcing technique\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rvl3n_Ry7ozF",
        "colab_type": "code",
        "outputId": "00e64099-f0fe-45b2-c6f0-7731c9da9683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "BUFFER_SIZE = len(input_data)\n",
        "BATCH_SIZE = 128\n",
        "embedding_dim = 300\n",
        "units = 128\n",
        "vocab_in_size = len(input_lang.word2idx)\n",
        "vocab_out_size = len(target_lang.word2idx)\n",
        "df.iloc[30:65]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; look at their hands while hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair l &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ook at their hands while hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair lo &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ok at their hands while hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair loo &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; k at their hands while hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;  at their hands while hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; at their hands while hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look a &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; t their hands while hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;  their hands while hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; their hands while hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at t &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; heir hands while hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at th &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; eir hands while hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at the &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ir hands while hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at thei &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; r hands while hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at their &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;  hands while hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at their  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; hands while hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at their h &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ands while hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at their ha &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; nds while hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at their han &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ds while hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at their hand &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; s while hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at their hands &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;  while hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at their hands  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; while hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at their hands w &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; hile hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at their hands wh &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ile hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at their hands whi &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; le hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at their hands whil &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; e hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at their hands while &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;  hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at their hands while  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; hanging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at their hands while h &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; anging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at their hands while ha &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; nging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at their hands while han &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ging out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at their hands while hang &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ing out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at their hands while hangi &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ng out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at their hands while hangin &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; g out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at their hands while hanging &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;  out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>&lt;start&gt; two young guys with shaggy hair look at their hands while hanging  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; out in the yard . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                               input                                                             output\n",
              "30  <start> two young guys with shaggy hair  <end>                                    <start> look at their hands while hanging out in the yard . <end>\n",
              "31  <start> two young guys with shaggy hair l <end>                                   <start> ook at their hands while hanging out in the yard . <end> \n",
              "32  <start> two young guys with shaggy hair lo <end>                                  <start> ok at their hands while hanging out in the yard . <end>  \n",
              "33  <start> two young guys with shaggy hair loo <end>                                 <start> k at their hands while hanging out in the yard . <end>   \n",
              "34  <start> two young guys with shaggy hair look <end>                                <start>  at their hands while hanging out in the yard . <end>    \n",
              "35  <start> two young guys with shaggy hair look  <end>                               <start> at their hands while hanging out in the yard . <end>     \n",
              "36  <start> two young guys with shaggy hair look a <end>                              <start> t their hands while hanging out in the yard . <end>      \n",
              "37  <start> two young guys with shaggy hair look at <end>                             <start>  their hands while hanging out in the yard . <end>       \n",
              "38  <start> two young guys with shaggy hair look at  <end>                            <start> their hands while hanging out in the yard . <end>        \n",
              "39  <start> two young guys with shaggy hair look at t <end>                           <start> heir hands while hanging out in the yard . <end>         \n",
              "40  <start> two young guys with shaggy hair look at th <end>                          <start> eir hands while hanging out in the yard . <end>          \n",
              "41  <start> two young guys with shaggy hair look at the <end>                         <start> ir hands while hanging out in the yard . <end>           \n",
              "42  <start> two young guys with shaggy hair look at thei <end>                        <start> r hands while hanging out in the yard . <end>            \n",
              "43  <start> two young guys with shaggy hair look at their <end>                       <start>  hands while hanging out in the yard . <end>             \n",
              "44  <start> two young guys with shaggy hair look at their  <end>                      <start> hands while hanging out in the yard . <end>              \n",
              "45  <start> two young guys with shaggy hair look at their h <end>                     <start> ands while hanging out in the yard . <end>               \n",
              "46  <start> two young guys with shaggy hair look at their ha <end>                    <start> nds while hanging out in the yard . <end>                \n",
              "47  <start> two young guys with shaggy hair look at their han <end>                   <start> ds while hanging out in the yard . <end>                 \n",
              "48  <start> two young guys with shaggy hair look at their hand <end>                  <start> s while hanging out in the yard . <end>                  \n",
              "49  <start> two young guys with shaggy hair look at their hands <end>                 <start>  while hanging out in the yard . <end>                   \n",
              "50  <start> two young guys with shaggy hair look at their hands  <end>                <start> while hanging out in the yard . <end>                    \n",
              "51  <start> two young guys with shaggy hair look at their hands w <end>               <start> hile hanging out in the yard . <end>                     \n",
              "52  <start> two young guys with shaggy hair look at their hands wh <end>              <start> ile hanging out in the yard . <end>                      \n",
              "53  <start> two young guys with shaggy hair look at their hands whi <end>             <start> le hanging out in the yard . <end>                       \n",
              "54  <start> two young guys with shaggy hair look at their hands whil <end>            <start> e hanging out in the yard . <end>                        \n",
              "55  <start> two young guys with shaggy hair look at their hands while <end>           <start>  hanging out in the yard . <end>                         \n",
              "56  <start> two young guys with shaggy hair look at their hands while  <end>          <start> hanging out in the yard . <end>                          \n",
              "57  <start> two young guys with shaggy hair look at their hands while h <end>         <start> anging out in the yard . <end>                           \n",
              "58  <start> two young guys with shaggy hair look at their hands while ha <end>        <start> nging out in the yard . <end>                            \n",
              "59  <start> two young guys with shaggy hair look at their hands while han <end>       <start> ging out in the yard . <end>                             \n",
              "60  <start> two young guys with shaggy hair look at their hands while hang <end>      <start> ing out in the yard . <end>                              \n",
              "61  <start> two young guys with shaggy hair look at their hands while hangi <end>     <start> ng out in the yard . <end>                               \n",
              "62  <start> two young guys with shaggy hair look at their hands while hangin <end>    <start> g out in the yard . <end>                                \n",
              "63  <start> two young guys with shaggy hair look at their hands while hanging <end>   <start>  out in the yard . <end>                                 \n",
              "64  <start> two young guys with shaggy hair look at their hands while hanging  <end>  <start> out in the yard . <end>                                  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C-w5YEB7rme",
        "colab_type": "code",
        "outputId": "6a9b94c5-fb43-43a6-fac2-8414abf79267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        }
      },
      "source": [
        "# Create the Encoder layers first.\n",
        "encoder_inputs = Input(shape=(len_input,))\n",
        "encoder_emb = Embedding(input_dim=vocab_in_size, output_dim=embedding_dim)\n",
        "\n",
        "# Use this if you dont need Bidirectional LSTM\n",
        "# encoder_lstm = CuDNNLSTM(units=units, return_sequences=True, return_state=True)\n",
        "# encoder_out, state_h, state_c = encoder_lstm(encoder_emb(encoder_inputs))\n",
        "\n",
        "encoder_lstm = Bidirectional(CuDNNLSTM(units=units, return_sequences=True, return_state=True))\n",
        "encoder_out, fstate_h, fstate_c, bstate_h, bstate_c = encoder_lstm(encoder_emb(encoder_inputs))\n",
        "state_h = Concatenate()([fstate_h,bstate_h])\n",
        "state_c = Concatenate()([bstate_h,bstate_c])\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "\n",
        "# Now create the Decoder layers.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_emb = Embedding(input_dim=vocab_out_size, output_dim=embedding_dim)\n",
        "decoder_lstm = CuDNNLSTM(units=units*2, return_sequences=True, return_state=True)\n",
        "decoder_lstm_out, _, _ = decoder_lstm(decoder_emb(decoder_inputs), initial_state=encoder_states)\n",
        "# Two dense layers added to this model to improve inference capabilities.\n",
        "decoder_d1 = Dense(units, activation=\"relu\")\n",
        "decoder_d2 = Dense(vocab_out_size, activation=\"softmax\")\n",
        "decoder_out = decoder_d2(Dropout(rate=.2)(decoder_d1(Dropout(rate=.2)(decoder_lstm_out))))\n",
        "\n",
        "\n",
        "# Finally, create a training model which combines the encoder and the decoder.\n",
        "# Note that this model has three inputs:\n",
        "model = Model(inputs = [encoder_inputs, decoder_inputs], outputs= decoder_out)\n",
        "\n",
        "# We'll use sparse_categorical_crossentropy so we don't have to expand decoder_out into a massive one-hot array.\n",
        "# Adam is used because it's, well, the best.\n",
        "\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(), loss=\"sparse_categorical_crossentropy\", metrics=['sparse_categorical_accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0904 11:14:44.267354 139904885905280 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0904 11:14:44.273041 139904885905280 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0904 11:14:44.280266 139904885905280 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0904 11:14:44.281475 139904885905280 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0904 11:14:44.282709 139904885905280 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 57)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 57, 300)      2526600     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   [(None, 57, 256), (N 440320      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    2585700     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256)          0           bidirectional[0][1]              \n",
            "                                                                 bidirectional[0][3]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256)          0           bidirectional[0][3]              \n",
            "                                                                 bidirectional[0][4]              \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_1 (CuDNNLSTM)        [(None, None, 256),  571392      embedding_1[0][0]                \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, None, 256)    0           cu_dnnlstm_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 128)    32896       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, None, 128)    0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 8619)   1111851     dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,268,759\n",
            "Trainable params: 7,268,759\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7djduHe7uPB",
        "colab_type": "code",
        "outputId": "acf65b6d-8298-4149-f5a0-7a1fca48a7b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Note, we use 20% of our data for validation.\n",
        "epochs = 30\n",
        "history = model.fit([input_data, teacher_data], target_data,\n",
        "                 batch_size= BATCH_SIZE,\n",
        "                 epochs=epochs,\n",
        "                 validation_split=0.2)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 124768 samples, validate on 31192 samples\n",
            "Epoch 1/30\n",
            "124768/124768 [==============================] - 241s 2ms/sample - loss: 0.6587 - sparse_categorical_accuracy: 0.8905 - val_loss: 0.5414 - val_sparse_categorical_accuracy: 0.9005\n",
            "Epoch 2/30\n",
            "124768/124768 [==============================] - 242s 2ms/sample - loss: 0.4788 - sparse_categorical_accuracy: 0.9067 - val_loss: 0.3812 - val_sparse_categorical_accuracy: 0.9209\n",
            "Epoch 3/30\n",
            "124768/124768 [==============================] - 243s 2ms/sample - loss: 0.3552 - sparse_categorical_accuracy: 0.9249 - val_loss: 0.2817 - val_sparse_categorical_accuracy: 0.9408\n",
            "Epoch 4/30\n",
            "124768/124768 [==============================] - 243s 2ms/sample - loss: 0.2767 - sparse_categorical_accuracy: 0.9394 - val_loss: 0.2242 - val_sparse_categorical_accuracy: 0.9519\n",
            "Epoch 5/30\n",
            "124768/124768 [==============================] - 244s 2ms/sample - loss: 0.2266 - sparse_categorical_accuracy: 0.9490 - val_loss: 0.1899 - val_sparse_categorical_accuracy: 0.9588\n",
            "Epoch 6/30\n",
            "124768/124768 [==============================] - 244s 2ms/sample - loss: 0.1929 - sparse_categorical_accuracy: 0.9555 - val_loss: 0.1660 - val_sparse_categorical_accuracy: 0.9638\n",
            "Epoch 7/30\n",
            "124768/124768 [==============================] - 244s 2ms/sample - loss: 0.1692 - sparse_categorical_accuracy: 0.9602 - val_loss: 0.1497 - val_sparse_categorical_accuracy: 0.9673\n",
            "Epoch 8/30\n",
            "124768/124768 [==============================] - 244s 2ms/sample - loss: 0.1515 - sparse_categorical_accuracy: 0.9638 - val_loss: 0.1376 - val_sparse_categorical_accuracy: 0.9698\n",
            "Epoch 9/30\n",
            "124768/124768 [==============================] - 243s 2ms/sample - loss: 0.1378 - sparse_categorical_accuracy: 0.9667 - val_loss: 0.1290 - val_sparse_categorical_accuracy: 0.9717\n",
            "Epoch 10/30\n",
            "124768/124768 [==============================] - 242s 2ms/sample - loss: 0.1270 - sparse_categorical_accuracy: 0.9689 - val_loss: 0.1220 - val_sparse_categorical_accuracy: 0.9733\n",
            "Epoch 11/30\n",
            "124768/124768 [==============================] - 243s 2ms/sample - loss: 0.1180 - sparse_categorical_accuracy: 0.9707 - val_loss: 0.1168 - val_sparse_categorical_accuracy: 0.9747\n",
            "Epoch 12/30\n",
            "124768/124768 [==============================] - 243s 2ms/sample - loss: 0.1107 - sparse_categorical_accuracy: 0.9722 - val_loss: 0.1125 - val_sparse_categorical_accuracy: 0.9755\n",
            "Epoch 13/30\n",
            "124768/124768 [==============================] - 243s 2ms/sample - loss: 0.1045 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.1100 - val_sparse_categorical_accuracy: 0.9762\n",
            "Epoch 14/30\n",
            "124768/124768 [==============================] - 243s 2ms/sample - loss: 0.0991 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.1056 - val_sparse_categorical_accuracy: 0.9772\n",
            "Epoch 15/30\n",
            "124768/124768 [==============================] - 243s 2ms/sample - loss: 0.0946 - sparse_categorical_accuracy: 0.9758 - val_loss: 0.1026 - val_sparse_categorical_accuracy: 0.9778\n",
            "Epoch 16/30\n",
            "124768/124768 [==============================] - 243s 2ms/sample - loss: 0.0906 - sparse_categorical_accuracy: 0.9767 - val_loss: 0.1011 - val_sparse_categorical_accuracy: 0.9785\n",
            "Epoch 17/30\n",
            "124768/124768 [==============================] - 243s 2ms/sample - loss: 0.0871 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0993 - val_sparse_categorical_accuracy: 0.9790\n",
            "Epoch 18/30\n",
            "124768/124768 [==============================] - 243s 2ms/sample - loss: 0.0840 - sparse_categorical_accuracy: 0.9782 - val_loss: 0.0975 - val_sparse_categorical_accuracy: 0.9794\n",
            "Epoch 19/30\n",
            "124768/124768 [==============================] - 243s 2ms/sample - loss: 0.0812 - sparse_categorical_accuracy: 0.9788 - val_loss: 0.0965 - val_sparse_categorical_accuracy: 0.9798\n",
            "Epoch 20/30\n",
            "124768/124768 [==============================] - 243s 2ms/sample - loss: 0.0788 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0954 - val_sparse_categorical_accuracy: 0.9801\n",
            "Epoch 21/30\n",
            "124768/124768 [==============================] - 243s 2ms/sample - loss: 0.0765 - sparse_categorical_accuracy: 0.9800 - val_loss: 0.0939 - val_sparse_categorical_accuracy: 0.9804\n",
            "Epoch 22/30\n",
            "124768/124768 [==============================] - 242s 2ms/sample - loss: 0.0742 - sparse_categorical_accuracy: 0.9805 - val_loss: 0.0926 - val_sparse_categorical_accuracy: 0.9807\n",
            "Epoch 23/30\n",
            "124768/124768 [==============================] - 243s 2ms/sample - loss: 0.0725 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.0923 - val_sparse_categorical_accuracy: 0.9809\n",
            "Epoch 24/30\n",
            "124768/124768 [==============================] - 243s 2ms/sample - loss: 0.0706 - sparse_categorical_accuracy: 0.9814 - val_loss: 0.0912 - val_sparse_categorical_accuracy: 0.9812\n",
            "Epoch 25/30\n",
            "124768/124768 [==============================] - 243s 2ms/sample - loss: 0.0692 - sparse_categorical_accuracy: 0.9817 - val_loss: 0.0901 - val_sparse_categorical_accuracy: 0.9816\n",
            "Epoch 26/30\n",
            "124768/124768 [==============================] - 243s 2ms/sample - loss: 0.0675 - sparse_categorical_accuracy: 0.9822 - val_loss: 0.0902 - val_sparse_categorical_accuracy: 0.9816\n",
            "Epoch 27/30\n",
            "124768/124768 [==============================] - 243s 2ms/sample - loss: 0.0661 - sparse_categorical_accuracy: 0.9825 - val_loss: 0.0890 - val_sparse_categorical_accuracy: 0.9821\n",
            "Epoch 28/30\n",
            "124768/124768 [==============================] - 243s 2ms/sample - loss: 0.0649 - sparse_categorical_accuracy: 0.9828 - val_loss: 0.0883 - val_sparse_categorical_accuracy: 0.9821\n",
            "Epoch 29/30\n",
            "124768/124768 [==============================] - 243s 2ms/sample - loss: 0.0635 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.0884 - val_sparse_categorical_accuracy: 0.9822\n",
            "Epoch 30/30\n",
            "124768/124768 [==============================] - 243s 2ms/sample - loss: 0.0624 - sparse_categorical_accuracy: 0.9834 - val_loss: 0.0874 - val_sparse_categorical_accuracy: 0.9824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp2G6QgE74WX",
        "colab_type": "code",
        "outputId": "6a0245e2-6564-45d7-d6d7-27f004b14611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# Plot the results of the training.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label=\"Training loss\")\n",
        "plt.plot(history.history['val_loss'], label=\"Validation loss\")\n",
        "plt.show()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLiLiQwp3EREfUriLiPiQwl1ExIf+P+13Bs+sZ+dEAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5-UamSb8G3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Create the encoder model from the tensors we previously declared.\n",
        "encoder_model = Model(encoder_inputs, [encoder_out, state_h, state_c])\n",
        "\n",
        "# Generate a new set of tensors for our new inference decoder. Note that we are using new tensors, \n",
        "# this does not preclude using the same underlying layers that we trained on. (e.g. weights/biases).\n",
        "\n",
        "inf_decoder_inputs = Input(shape=(None,), name=\"inf_decoder_inputs\")\n",
        "# We'll need to force feed the two state variables into the decoder each step.\n",
        "state_input_h = Input(shape=(units*2,), name=\"state_input_h\")\n",
        "state_input_c = Input(shape=(units*2,), name=\"state_input_c\")\n",
        "decoder_res, decoder_h, decoder_c = decoder_lstm(\n",
        "    decoder_emb(inf_decoder_inputs), \n",
        "    initial_state=[state_input_h, state_input_c])\n",
        "inf_decoder_out = decoder_d2(decoder_d1(decoder_res))\n",
        "inf_model = Model(inputs=[inf_decoder_inputs, state_input_h, state_input_c], \n",
        "                  outputs=[inf_decoder_out, decoder_h, decoder_c])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjvkGbFG8Lqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converts the given sentence (just a string) into a vector of word IDs\n",
        "# Output is 1-D: [timesteps/words]\n",
        "\n",
        "def sentence_to_vector(sentence, lang):\n",
        "\n",
        "    pre = sentence\n",
        "    vec = np.zeros(len_input)\n",
        "    sentence_list = [lang.word2idx[s] for s in pre.split(' ')]\n",
        "    for i,w in enumerate(sentence_list):\n",
        "        vec[i] = w\n",
        "    return vec\n",
        "\n",
        "# Given an input string, an encoder model (infenc_model) and a decoder model (infmodel),\n",
        "def translate(input_sentence, infenc_model, infmodel):\n",
        "    sv = sentence_to_vector(input_sentence, input_lang)\n",
        "    sv = sv.reshape(1,len(sv))\n",
        "    [emb_out, sh, sc] = infenc_model.predict(x=sv)\n",
        "    \n",
        "    i = 0\n",
        "    start_vec = target_lang.word2idx[\"<start>\"]\n",
        "    stop_vec = target_lang.word2idx[\"<end>\"]\n",
        "    \n",
        "    cur_vec = np.zeros((1,1))\n",
        "    cur_vec[0,0] = start_vec\n",
        "    cur_word = \"<start>\"\n",
        "    output_sentence = \"\"\n",
        "\n",
        "    while cur_word != \"<end>\" and i < (len_target-1):\n",
        "        i += 1\n",
        "        if cur_word != \"<start>\":\n",
        "            output_sentence = output_sentence + \" \" + cur_word\n",
        "        x_in = [cur_vec, sh, sc]\n",
        "        [nvec, sh, sc] = infmodel.predict(x=x_in)\n",
        "        cur_vec[0,0] = np.argmax(nvec[0,0])\n",
        "        cur_word = target_lang.idx2word[np.argmax(nvec[0,0])]\n",
        "    return output_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQuHwOof8QjF",
        "colab_type": "code",
        "outputId": "e580f1ae-0107-480a-d601-bed01ccfb14a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 909
        }
      },
      "source": [
        "#Note that only words that we've trained the model on will be available, otherwise you'll get an error.\n",
        "\n",
        "\n",
        "# test = [\n",
        "#     'hi there',\n",
        "#     'hell',\n",
        "#     'presentation please fin',\n",
        "#     'resignation please find at',\n",
        "#     'resignation please ',\n",
        "#     'have a nice we',\n",
        "#     'let me ',\n",
        "#     'promotion congrats ',\n",
        "#     'christmas Merry ',\n",
        "#     'please rev',\n",
        "#     'please ca',\n",
        "#     'thanks fo',\n",
        "#     'Let me kno',\n",
        "#     'Let me know if y',\n",
        "#     'this soun',\n",
        "#     'is this call going t'\n",
        "# ]\n",
        "\n",
        "test = [\n",
        "    'A woman wearing a bl',\n",
        "    'A man wor',\n",
        "    'A man is instr',\n",
        "    'A city str',\n",
        "    'A large man wea',\n",
        "    'Man remov',\n",
        "    'Seve',\n",
        "    'person is atte',\n",
        "    'wearing je',\n",
        "    'standing out',\n",
        "    'people in different co',\n",
        "    'dog ru',\n",
        "    'biker is ri',\n",
        "    'Blond girl in a yel',\n",
        "    'A person is walking al',\n",
        "    'A you',\n",
        "    'A young fem',\n",
        "    'A young female i',\n",
        "    'A young female is si',\n",
        "    'A young female is sitting i',\n",
        "    'A young female is sitting in a c',\n",
        "    'A young female is sitting in a chair o',\n",
        "    'A young female is sitting in a chair on th',\n",
        "    'A young female is sitting in a chair on the be',\n",
        "    'A young female is sitting in a chair on the beach , wh'\n",
        "]\n",
        "  \n",
        "\n",
        "import pandas as pd\n",
        "output = []  \n",
        "for t in test:  \n",
        "  output.append({\"Input seq\":t.lower(), \"Pred. Seq\":translate(t.lower(), encoder_model, inf_model)})\n",
        "\n",
        "results_df = pd.DataFrame.from_dict(output) \n",
        "results_df.head(len(test))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input seq</th>\n",
              "      <th>Pred. Seq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a woman wearing a bl</td>\n",
              "      <td>ack shirt and black pants is reading a book on a tank grill .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a man wor</td>\n",
              "      <td>ks on a project using a jigsaw cutting machine .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a man is instr</td>\n",
              "      <td>it in a green shirt and a little boy in a bathing suit playing in the sand .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a city str</td>\n",
              "      <td>an is performing a trick in restaurant .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a large man wea</td>\n",
              "      <td>an illinois tshirt is looking at a camera while a girl is aiming her foot at his face and another man is making an odd face in the background .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>man remov</td>\n",
              "      <td>ing a reflective vest sits on the sidewalk and laughing .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>seve</td>\n",
              "      <td>ral people are taking a break while on a snowmobiling ride .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>person is atte</td>\n",
              "      <td>ating a burger while the man next to her touching his hat .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>wearing je</td>\n",
              "      <td>oy in a blue shirt and red hat is looking at his thumb on one hand while holding glasses in his other hand .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>standing out</td>\n",
              "      <td>ired man in a suit , with a blue bucket and shovel on the shore of the ocean .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>people in different co</td>\n",
              "      <td>ess converse with a man at the scene of an emergency .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>dog ru</td>\n",
              "      <td>jumping over a small wall at a beach near the water .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>biker is ri</td>\n",
              "      <td>on the ground in front of the street .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>blond girl in a yel</td>\n",
              "      <td>ue shirt and black shorts is wearing headphones .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>a person is walking al</td>\n",
              "      <td>ong a lake with houses in the distance .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>a you</td>\n",
              "      <td>te boy in a blue shirt and yellow pants is looking out at the camera , is ready to catch him .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>a young fem</td>\n",
              "      <td>ale student performing a downward kick to break a board held by her karate instructor .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>a young female i</td>\n",
              "      <td>n a gray jacket and jeans , working on a horse 's shoe .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>a young female is si</td>\n",
              "      <td>tting up a chainsaw .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>a young female is sitting i</td>\n",
              "      <td>nside a rock climbing wall on a scaffold .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>a young female is sitting in a c</td>\n",
              "      <td>troller on a nice summer day .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>a young female is sitting in a chair o</td>\n",
              "      <td>alk in a tropical setting .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>a young female is sitting in a chair on th</td>\n",
              "      <td>e sidewalk in an upscale restaurant .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>a young female is sitting in a chair on the be</td>\n",
              "      <td>ach in front of a fence .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>a young female is sitting in a chair on the beach , wh</td>\n",
              "      <td>ile a man behind him seems to be laughing very hard and the woman on the right has a big smile on her face .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Input seq                                                                                                                                         Pred. Seq\n",
              "0   a woman wearing a bl                                     ack shirt and black pants is reading a book on a tank grill .                                                                                  \n",
              "1   a man wor                                                ks on a project using a jigsaw cutting machine .                                                                                               \n",
              "2   a man is instr                                           it in a green shirt and a little boy in a bathing suit playing in the sand .                                                                   \n",
              "3   a city str                                               an is performing a trick in restaurant .                                                                                                       \n",
              "4   a large man wea                                          an illinois tshirt is looking at a camera while a girl is aiming her foot at his face and another man is making an odd face in the background .\n",
              "5   man remov                                                ing a reflective vest sits on the sidewalk and laughing .                                                                                      \n",
              "6   seve                                                     ral people are taking a break while on a snowmobiling ride .                                                                                   \n",
              "7   person is atte                                           ating a burger while the man next to her touching his hat .                                                                                    \n",
              "8   wearing je                                               oy in a blue shirt and red hat is looking at his thumb on one hand while holding glasses in his other hand .                                   \n",
              "9   standing out                                             ired man in a suit , with a blue bucket and shovel on the shore of the ocean .                                                                 \n",
              "10  people in different co                                   ess converse with a man at the scene of an emergency .                                                                                         \n",
              "11  dog ru                                                   jumping over a small wall at a beach near the water .                                                                                          \n",
              "12  biker is ri                                              on the ground in front of the street .                                                                                                         \n",
              "13  blond girl in a yel                                      ue shirt and black shorts is wearing headphones .                                                                                              \n",
              "14  a person is walking al                                   ong a lake with houses in the distance .                                                                                                       \n",
              "15  a you                                                    te boy in a blue shirt and yellow pants is looking out at the camera , is ready to catch him .                                                 \n",
              "16  a young fem                                              ale student performing a downward kick to break a board held by her karate instructor .                                                        \n",
              "17  a young female i                                         n a gray jacket and jeans , working on a horse 's shoe .                                                                                       \n",
              "18  a young female is si                                     tting up a chainsaw .                                                                                                                          \n",
              "19  a young female is sitting i                              nside a rock climbing wall on a scaffold .                                                                                                     \n",
              "20  a young female is sitting in a c                         troller on a nice summer day .                                                                                                                 \n",
              "21  a young female is sitting in a chair o                   alk in a tropical setting .                                                                                                                    \n",
              "22  a young female is sitting in a chair on th               e sidewalk in an upscale restaurant .                                                                                                          \n",
              "23  a young female is sitting in a chair on the be           ach in front of a fence .                                                                                                                      \n",
              "24  a young female is sitting in a chair on the beach , wh   ile a man behind him seems to be laughing very hard and the woman on the right has a big smile on her face .                                   "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_10pgS38Udd",
        "colab_type": "code",
        "outputId": "e352ad4f-f2c6-45a0-effd-f7a223bd65b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# This is to save the model for the web app to use for generation\n",
        "from keras.models import model_from_json\n",
        "from keras.models import load_model\n",
        "\n",
        "# serialize model to JSON\n",
        "#  the keras model which is trained is defined as 'model' in this example\n",
        "model_json = inf_model.to_json()\n",
        "\n",
        "\n",
        "with open(\"./sample_data/model_num.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# serialize weights to HDF5\n",
        "inf_model.save_weights(\"./sample_data/model_num.h5\")"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTdUt__J9UFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}