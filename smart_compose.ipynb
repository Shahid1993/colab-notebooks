{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conditional_gen.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahid1993/colab-notebooks/blob/master/smart_compose.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rqIkznPzTz0",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing Enron Email Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzYmnnl-eGVh",
        "colab_type": "code",
        "outputId": "61a7c94a-942e-48be-ad18-e43c664473ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "#To mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-iD8N7-F596",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip ./sample_data/enron-email-dataset.zip -d ./sample_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3eWjasEzZRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNsSBHu-zlsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data = pd.read_csv(\"./sample_data/emails.csv\")\n",
        "# pd.set_option('display.max_colwidth',-1)\n",
        "# new = data[\"message\"].str.split(\"\\n\", n = 15, expand = True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnugzK2gzm4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#new.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEC0CgIL6Acj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYNW0xkU6Ie2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data[\"from\"] = new[2]\n",
        "# data[\"fromn\"] = new[8]\n",
        "# data[\"to\"] = new[3]\n",
        "# data[\"ton\"] = new[9]\n",
        "# data[\"subject\"] = new[4]\n",
        "# data[\"msg\"] = new[15]\n",
        "# data.drop(columns =[\"message\"], inplace = True) \n",
        "# data.drop(columns =[\"file\"], inplace = True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd5yfsGn6Nyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbmQc_Ox6Pg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data['from'] = data[\"from\"].apply(lambda val: val.replace(\"From:\",''))\n",
        "# data['fromn'] = data[\"fromn\"].apply(lambda val: val.replace(\"X-From:\",''))\n",
        "# data['to'] = data[\"to\"].apply(lambda val: val.replace(\"To:\",''))\n",
        "# data['ton'] = data[\"ton\"].apply(lambda val: val.replace(\"X-To:\",''))\n",
        "# data['subject'] = data[\"subject\"].apply(lambda val: val.replace(\"Subject:\",''))\n",
        "# data['msg'] = data[\"msg\"].apply(lambda val: val.replace(\"\\n\",' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIqBN7PL6U0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKZVxfIo6XEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets look only at emails with 100 words or less and that are Non-replies\n",
        "# data[(data['msg'].str.len() <100) & ~(data['subject'].str.contains('Re:'))].sample(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pic0sVy6b-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data.head()['msg']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwE8cjrn7JOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# corpus = [msg for msg in data[(data['msg'].str.len() <100) & ~(data['subject'].str.contains('Re:'))]['msg']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWfxURtp7KLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# corpus[60:69]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCxtqjoZ7OMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bml4t8rhpYNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Taking only as subset of corpus, since it takes lot of time for training\n",
        "# corpus = corpus[0:10000]\n",
        "\n",
        "file = open(\"./drive/My Drive/ML/data/smart_compose.txt\", 'r')\n",
        "corpus = [line for line in file]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yux4w690psbF",
        "colab_type": "code",
        "outputId": "64d8e180-1ebb-413d-9c6d-f7cfa87f6315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(corpus)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "158915"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBVsx5tzwJlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import sample\n",
        "\n",
        "corpus = sample(corpus, 2500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogYG1CYfwh2y",
        "colab_type": "code",
        "outputId": "38331fbd-6903-4c8d-9925-5ce33ecf3448",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(corpus)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmEO0eHAwk-l",
        "colab_type": "code",
        "outputId": "4d74689f-9641-4c92-ce30-0eda54b074b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "corpus[60:75]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A man , woman and three bicycles are resting by a silver car .\\n',\n",
              " 'Several women are wrapping themselves up in pink , blue and white ribbon .\\n',\n",
              " 'A young man takes aim in a carnival game .\\n',\n",
              " 'A woman is smiling holding up a Spiderman shirt .\\n',\n",
              " 'A woman cutting fabric flowers in a market .\\n',\n",
              " 'There is a carpenter measuring a board .\\n',\n",
              " 'Two construction workers are sitting up on the side of a building .\\n',\n",
              " '2 men and a woman who is wearing red are holding a surfboard standing in the sand .\\n',\n",
              " 'a surfer is riding the waves whilst another surfer sits on his board waiting .\\n',\n",
              " 'Field workers are working in a rice paddy .\\n',\n",
              " 'A motorcyclist is riding their sponsored car along a roadway that has recently turned .\\n',\n",
              " 'A young boy with a shaved head and dirty white collared shirt holds a chicken in his arm .\\n',\n",
              " 'Man and woman and others , with scary , gory makeup and holding fake brain walking down the street .\\n',\n",
              " 'A construction worker sits in a green lift .\\n',\n",
              " 'A couple walking down the street .\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0ZsBrqU7TwL",
        "colab_type": "code",
        "outputId": "9c473fa3-0ed1-4e47-ef6f-0f5735af1c53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Start by importing all the things we'll need.\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, CuDNNLSTM, Flatten, TimeDistributed, Dropout, LSTMCell, RNN, Bidirectional, Concatenate, Layer\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.python.keras.utils import tf_utils\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, os \n",
        "tf.__version__"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_RkYugZ7cig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_special_chars(text, punct):\n",
        "    for p in punct:\n",
        "        text = text.replace(p, '')\n",
        "    return text\n",
        "\n",
        "      \n",
        "def preprocess(data):\n",
        "    output = []\n",
        "    punct = '#$%&*+-/<=>@[\\\\]^_`{|}~\\t\\n'\n",
        "    for line in data:\n",
        "         pline= clean_special_chars(line.lower(), punct)\n",
        "         output.append(pline)\n",
        "    return output  \n",
        "\n",
        "\n",
        "def generate_dataset():\n",
        "  \n",
        "    processed_corpus = preprocess(corpus)    \n",
        "    output = []\n",
        "    for line in processed_corpus:\n",
        "        token_list = line\n",
        "        for i in range(1, len(token_list)):\n",
        "            data = []\n",
        "            x_ngram = '<start> '+ token_list[:i+1] + ' <end>'\n",
        "            y_ngram = '<start> '+ token_list[i+1:] + ' <end>'\n",
        "            data.append(x_ngram)\n",
        "            data.append(y_ngram)\n",
        "            output.append(data)\n",
        "    print(\"Dataset prepared with prefix and suffixes for teacher forcing technique\")\n",
        "    dummy_df = pd.DataFrame(output, columns=['input','output'])\n",
        "    return output, dummy_df            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xrqss6-7kGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LanguageIndex():\n",
        "    def __init__(self, lang):\n",
        "        self.lang = lang\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "    def create_index(self):\n",
        "        for phrase in self.lang:\n",
        "            self.vocab.update(phrase.split(' '))\n",
        "        self.vocab = sorted(self.vocab)\n",
        "        self.word2idx[\"<pad>\"] = 0\n",
        "        self.idx2word[0] = \"<pad>\"\n",
        "        for i,word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = i + 1\n",
        "            self.idx2word[i+1] = word\n",
        "\n",
        "def max_length(t):\n",
        "    return max(len(i) for i in t)\n",
        "\n",
        "def load_dataset():\n",
        "    pairs,df = generate_dataset()\n",
        "    out_lang = LanguageIndex(sp for en, sp in pairs)\n",
        "    in_lang = LanguageIndex(en for en, sp in pairs)\n",
        "    input_data = [[in_lang.word2idx[s] for s in en.split(' ')] for en, sp in pairs]\n",
        "    output_data = [[out_lang.word2idx[s] for s in sp.split(' ')] for en, sp in pairs]\n",
        "\n",
        "    max_length_in, max_length_out = max_length(input_data), max_length(output_data)\n",
        "    input_data = tf.keras.preprocessing.sequence.pad_sequences(input_data, maxlen=max_length_in, padding=\"post\")\n",
        "    output_data = tf.keras.preprocessing.sequence.pad_sequences(output_data, maxlen=max_length_out, padding=\"post\")\n",
        "    return input_data, output_data, in_lang, out_lang, max_length_in, max_length_out, df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBUsKoAB7mIX",
        "colab_type": "code",
        "outputId": "d9693075-0a18-4a2e-a9b4-173b67317efe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input_data, teacher_data, input_lang, target_lang, len_input, len_target, df = load_dataset()\n",
        "\n",
        "\n",
        "target_data = [[teacher_data[n][i+1] for i in range(len(teacher_data[n])-1)] for n in range(len(teacher_data))]\n",
        "target_data = tf.keras.preprocessing.sequence.pad_sequences(target_data, maxlen=len_target, padding=\"post\")\n",
        "target_data = target_data.reshape((target_data.shape[0], target_data.shape[1], 1))\n",
        "\n",
        "# Shuffle all of the data in unison. This training set has the longest (e.g. most complicated) data at the end,\n",
        "# so a simple Keras validation split will be problematic if not shuffled.\n",
        "\n",
        "p = np.random.permutation(len(input_data))\n",
        "input_data = input_data[p]\n",
        "teacher_data = teacher_data[p]\n",
        "target_data = target_data[p]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset prepared with prefix and suffixes for teacher forcing technique\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rvl3n_Ry7ozF",
        "colab_type": "code",
        "outputId": "b84d1dc3-80ab-44b0-875a-2dc00bb9da48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "BUFFER_SIZE = len(input_data)\n",
        "BATCH_SIZE = 128\n",
        "embedding_dim = 300\n",
        "units = 128\n",
        "vocab_in_size = len(input_lang.word2idx)\n",
        "vocab_out_size = len(target_lang.word2idx)\n",
        "df.iloc[30:65]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a rol &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ler coaster executes a spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roll &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; er coaster executes a spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a rolle &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; r coaster executes a spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;  coaster executes a spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; coaster executes a spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller c &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; oaster executes a spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller co &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; aster executes a spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coa &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ster executes a spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coas &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ter executes a spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coast &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; er executes a spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaste &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; r executes a spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;  executes a spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; executes a spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster e &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; xecutes a spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster ex &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ecutes a spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster exe &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; cutes a spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster exec &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; utes a spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster execu &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; tes a spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster execut &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; es a spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster execute &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; s a spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster executes &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;  a spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster executes  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; a spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster executes a &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;  spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster executes a  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; spiral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster executes a s &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; piral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster executes a sp &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; iral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster executes a spi &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ral looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster executes a spir &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; al looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster executes a spira &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; l looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster executes a spiral &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;  looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster executes a spiral  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; looptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster executes a spiral l &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ooptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster executes a spiral lo &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; optheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster executes a spiral loo &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ptheloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>&lt;start&gt; people hang upside down as a roller coaster executes a spiral loop &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; theloop . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                               input                                                     output\n",
              "30  <start> people hang upside down as a rol <end>                                    <start> ler coaster executes a spiral looptheloop . <end>\n",
              "31  <start> people hang upside down as a roll <end>                                   <start> er coaster executes a spiral looptheloop . <end> \n",
              "32  <start> people hang upside down as a rolle <end>                                  <start> r coaster executes a spiral looptheloop . <end>  \n",
              "33  <start> people hang upside down as a roller <end>                                 <start>  coaster executes a spiral looptheloop . <end>   \n",
              "34  <start> people hang upside down as a roller  <end>                                <start> coaster executes a spiral looptheloop . <end>    \n",
              "35  <start> people hang upside down as a roller c <end>                               <start> oaster executes a spiral looptheloop . <end>     \n",
              "36  <start> people hang upside down as a roller co <end>                              <start> aster executes a spiral looptheloop . <end>      \n",
              "37  <start> people hang upside down as a roller coa <end>                             <start> ster executes a spiral looptheloop . <end>       \n",
              "38  <start> people hang upside down as a roller coas <end>                            <start> ter executes a spiral looptheloop . <end>        \n",
              "39  <start> people hang upside down as a roller coast <end>                           <start> er executes a spiral looptheloop . <end>         \n",
              "40  <start> people hang upside down as a roller coaste <end>                          <start> r executes a spiral looptheloop . <end>          \n",
              "41  <start> people hang upside down as a roller coaster <end>                         <start>  executes a spiral looptheloop . <end>           \n",
              "42  <start> people hang upside down as a roller coaster  <end>                        <start> executes a spiral looptheloop . <end>            \n",
              "43  <start> people hang upside down as a roller coaster e <end>                       <start> xecutes a spiral looptheloop . <end>             \n",
              "44  <start> people hang upside down as a roller coaster ex <end>                      <start> ecutes a spiral looptheloop . <end>              \n",
              "45  <start> people hang upside down as a roller coaster exe <end>                     <start> cutes a spiral looptheloop . <end>               \n",
              "46  <start> people hang upside down as a roller coaster exec <end>                    <start> utes a spiral looptheloop . <end>                \n",
              "47  <start> people hang upside down as a roller coaster execu <end>                   <start> tes a spiral looptheloop . <end>                 \n",
              "48  <start> people hang upside down as a roller coaster execut <end>                  <start> es a spiral looptheloop . <end>                  \n",
              "49  <start> people hang upside down as a roller coaster execute <end>                 <start> s a spiral looptheloop . <end>                   \n",
              "50  <start> people hang upside down as a roller coaster executes <end>                <start>  a spiral looptheloop . <end>                    \n",
              "51  <start> people hang upside down as a roller coaster executes  <end>               <start> a spiral looptheloop . <end>                     \n",
              "52  <start> people hang upside down as a roller coaster executes a <end>              <start>  spiral looptheloop . <end>                      \n",
              "53  <start> people hang upside down as a roller coaster executes a  <end>             <start> spiral looptheloop . <end>                       \n",
              "54  <start> people hang upside down as a roller coaster executes a s <end>            <start> piral looptheloop . <end>                        \n",
              "55  <start> people hang upside down as a roller coaster executes a sp <end>           <start> iral looptheloop . <end>                         \n",
              "56  <start> people hang upside down as a roller coaster executes a spi <end>          <start> ral looptheloop . <end>                          \n",
              "57  <start> people hang upside down as a roller coaster executes a spir <end>         <start> al looptheloop . <end>                           \n",
              "58  <start> people hang upside down as a roller coaster executes a spira <end>        <start> l looptheloop . <end>                            \n",
              "59  <start> people hang upside down as a roller coaster executes a spiral <end>       <start>  looptheloop . <end>                             \n",
              "60  <start> people hang upside down as a roller coaster executes a spiral  <end>      <start> looptheloop . <end>                              \n",
              "61  <start> people hang upside down as a roller coaster executes a spiral l <end>     <start> ooptheloop . <end>                               \n",
              "62  <start> people hang upside down as a roller coaster executes a spiral lo <end>    <start> optheloop . <end>                                \n",
              "63  <start> people hang upside down as a roller coaster executes a spiral loo <end>   <start> ptheloop . <end>                                 \n",
              "64  <start> people hang upside down as a roller coaster executes a spiral loop <end>  <start> theloop . <end>                                  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C-w5YEB7rme",
        "colab_type": "code",
        "outputId": "d6ed5115-7ea1-4c03-cf38-0e0d9dba0632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        }
      },
      "source": [
        "# Create the Encoder layers first.\n",
        "encoder_inputs = Input(shape=(len_input,))\n",
        "encoder_emb = Embedding(input_dim=vocab_in_size, output_dim=embedding_dim)\n",
        "\n",
        "# Use this if you dont need Bidirectional LSTM\n",
        "# encoder_lstm = CuDNNLSTM(units=units, return_sequences=True, return_state=True)\n",
        "# encoder_out, state_h, state_c = encoder_lstm(encoder_emb(encoder_inputs))\n",
        "\n",
        "encoder_lstm = Bidirectional(CuDNNLSTM(units=units, return_sequences=True, return_state=True))\n",
        "encoder_out, fstate_h, fstate_c, bstate_h, bstate_c = encoder_lstm(encoder_emb(encoder_inputs))\n",
        "state_h = Concatenate()([fstate_h,bstate_h])\n",
        "state_c = Concatenate()([bstate_h,bstate_c])\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "\n",
        "# Now create the Decoder layers.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_emb = Embedding(input_dim=vocab_out_size, output_dim=embedding_dim)\n",
        "decoder_lstm = CuDNNLSTM(units=units*2, return_sequences=True, return_state=True)\n",
        "decoder_lstm_out, _, _ = decoder_lstm(decoder_emb(decoder_inputs), initial_state=encoder_states)\n",
        "# Two dense layers added to this model to improve inference capabilities.\n",
        "decoder_d1 = Dense(units, activation=\"relu\")\n",
        "decoder_d2 = Dense(vocab_out_size, activation=\"softmax\")\n",
        "decoder_out = decoder_d2(Dropout(rate=.2)(decoder_d1(Dropout(rate=.2)(decoder_lstm_out))))\n",
        "\n",
        "\n",
        "# Finally, create a training model which combines the encoder and the decoder.\n",
        "# Note that this model has three inputs:\n",
        "model = Model(inputs = [encoder_inputs, decoder_inputs], outputs= decoder_out)\n",
        "\n",
        "# We'll use sparse_categorical_crossentropy so we don't have to expand decoder_out into a massive one-hot array.\n",
        "# Adam is used because it's, well, the best.\n",
        "\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(), loss=\"sparse_categorical_crossentropy\", metrics=['sparse_categorical_accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 73)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 73, 300)      2942100     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   [(None, 73, 256), (N 440320      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    2985600     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256)          0           bidirectional[0][1]              \n",
            "                                                                 bidirectional[0][3]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256)          0           bidirectional[0][3]              \n",
            "                                                                 bidirectional[0][4]              \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_1 (CuDNNLSTM)        [(None, None, 256),  571392      embedding_1[0][0]                \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, None, 256)    0           cu_dnnlstm_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 128)    32896       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, None, 128)    0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 9952)   1283808     dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 8,256,116\n",
            "Trainable params: 8,256,116\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7djduHe7uPB",
        "colab_type": "code",
        "outputId": "9edb3a72-c23d-4a03-a6d4-8463ec3f6f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Note, we use 20% of our data for validation.\n",
        "epochs = 50\n",
        "history = model.fit([input_data, teacher_data], target_data,\n",
        "                 batch_size= BATCH_SIZE,\n",
        "                 epochs=epochs,\n",
        "                 validation_split=0.2)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 125222 samples, validate on 31306 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/50\n",
            "125222/125222 [==============================] - 358s 3ms/sample - loss: 0.6909 - sparse_categorical_accuracy: 0.9061 - val_loss: 0.4741 - val_sparse_categorical_accuracy: 0.9175\n",
            "Epoch 2/50\n",
            "125222/125222 [==============================] - 355s 3ms/sample - loss: 0.4220 - sparse_categorical_accuracy: 0.9223 - val_loss: 0.3443 - val_sparse_categorical_accuracy: 0.9321\n",
            "Epoch 3/50\n",
            "125222/125222 [==============================] - 355s 3ms/sample - loss: 0.3159 - sparse_categorical_accuracy: 0.9359 - val_loss: 0.2499 - val_sparse_categorical_accuracy: 0.9487\n",
            "Epoch 4/50\n",
            "125222/125222 [==============================] - 359s 3ms/sample - loss: 0.2417 - sparse_categorical_accuracy: 0.9484 - val_loss: 0.1933 - val_sparse_categorical_accuracy: 0.9597\n",
            "Epoch 5/50\n",
            "125222/125222 [==============================] - 356s 3ms/sample - loss: 0.1938 - sparse_categorical_accuracy: 0.9574 - val_loss: 0.1591 - val_sparse_categorical_accuracy: 0.9665\n",
            "Epoch 6/50\n",
            "125222/125222 [==============================] - 358s 3ms/sample - loss: 0.1618 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.1375 - val_sparse_categorical_accuracy: 0.9711\n",
            "Epoch 7/50\n",
            "125222/125222 [==============================] - 355s 3ms/sample - loss: 0.1394 - sparse_categorical_accuracy: 0.9680 - val_loss: 0.1220 - val_sparse_categorical_accuracy: 0.9744\n",
            "Epoch 8/50\n",
            "125222/125222 [==============================] - 358s 3ms/sample - loss: 0.1228 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.1115 - val_sparse_categorical_accuracy: 0.9766\n",
            "Epoch 9/50\n",
            "125222/125222 [==============================] - 355s 3ms/sample - loss: 0.1098 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.1032 - val_sparse_categorical_accuracy: 0.9785\n",
            "Epoch 10/50\n",
            "125222/125222 [==============================] - 357s 3ms/sample - loss: 0.0999 - sparse_categorical_accuracy: 0.9760 - val_loss: 0.0975 - val_sparse_categorical_accuracy: 0.9797\n",
            "Epoch 11/50\n",
            "125222/125222 [==============================] - 354s 3ms/sample - loss: 0.0918 - sparse_categorical_accuracy: 0.9777 - val_loss: 0.0924 - val_sparse_categorical_accuracy: 0.9810\n",
            "Epoch 12/50\n",
            "125222/125222 [==============================] - 357s 3ms/sample - loss: 0.0853 - sparse_categorical_accuracy: 0.9790 - val_loss: 0.0885 - val_sparse_categorical_accuracy: 0.9818\n",
            "Epoch 13/50\n",
            "125222/125222 [==============================] - 354s 3ms/sample - loss: 0.0797 - sparse_categorical_accuracy: 0.9802 - val_loss: 0.0858 - val_sparse_categorical_accuracy: 0.9825\n",
            "Epoch 14/50\n",
            "125222/125222 [==============================] - 357s 3ms/sample - loss: 0.0750 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0829 - val_sparse_categorical_accuracy: 0.9832\n",
            "Epoch 15/50\n",
            "125222/125222 [==============================] - 354s 3ms/sample - loss: 0.0710 - sparse_categorical_accuracy: 0.9822 - val_loss: 0.0819 - val_sparse_categorical_accuracy: 0.9836\n",
            "Epoch 16/50\n",
            "125222/125222 [==============================] - 357s 3ms/sample - loss: 0.0676 - sparse_categorical_accuracy: 0.9829 - val_loss: 0.0792 - val_sparse_categorical_accuracy: 0.9842\n",
            "Epoch 17/50\n",
            "125222/125222 [==============================] - 354s 3ms/sample - loss: 0.0646 - sparse_categorical_accuracy: 0.9836 - val_loss: 0.0778 - val_sparse_categorical_accuracy: 0.9847\n",
            "Epoch 18/50\n",
            "125222/125222 [==============================] - 357s 3ms/sample - loss: 0.0621 - sparse_categorical_accuracy: 0.9842 - val_loss: 0.0763 - val_sparse_categorical_accuracy: 0.9849\n",
            "Epoch 19/50\n",
            "125222/125222 [==============================] - 355s 3ms/sample - loss: 0.0597 - sparse_categorical_accuracy: 0.9847 - val_loss: 0.0758 - val_sparse_categorical_accuracy: 0.9852\n",
            "Epoch 20/50\n",
            "125222/125222 [==============================] - 357s 3ms/sample - loss: 0.0577 - sparse_categorical_accuracy: 0.9852 - val_loss: 0.0751 - val_sparse_categorical_accuracy: 0.9854\n",
            "Epoch 21/50\n",
            "125222/125222 [==============================] - 354s 3ms/sample - loss: 0.0558 - sparse_categorical_accuracy: 0.9857 - val_loss: 0.0746 - val_sparse_categorical_accuracy: 0.9857\n",
            "Epoch 22/50\n",
            "125222/125222 [==============================] - 357s 3ms/sample - loss: 0.0541 - sparse_categorical_accuracy: 0.9860 - val_loss: 0.0729 - val_sparse_categorical_accuracy: 0.9860\n",
            "Epoch 23/50\n",
            "125222/125222 [==============================] - 354s 3ms/sample - loss: 0.0526 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0723 - val_sparse_categorical_accuracy: 0.9862\n",
            "Epoch 24/50\n",
            "125222/125222 [==============================] - 356s 3ms/sample - loss: 0.0510 - sparse_categorical_accuracy: 0.9868 - val_loss: 0.0722 - val_sparse_categorical_accuracy: 0.9863\n",
            "Epoch 25/50\n",
            "125222/125222 [==============================] - 354s 3ms/sample - loss: 0.0498 - sparse_categorical_accuracy: 0.9871 - val_loss: 0.0714 - val_sparse_categorical_accuracy: 0.9865\n",
            "Epoch 26/50\n",
            "125222/125222 [==============================] - 356s 3ms/sample - loss: 0.0488 - sparse_categorical_accuracy: 0.9873 - val_loss: 0.0707 - val_sparse_categorical_accuracy: 0.9867\n",
            "Epoch 27/50\n",
            "125222/125222 [==============================] - 354s 3ms/sample - loss: 0.0475 - sparse_categorical_accuracy: 0.9877 - val_loss: 0.0702 - val_sparse_categorical_accuracy: 0.9869\n",
            "Epoch 28/50\n",
            "125222/125222 [==============================] - 357s 3ms/sample - loss: 0.0467 - sparse_categorical_accuracy: 0.9879 - val_loss: 0.0696 - val_sparse_categorical_accuracy: 0.9870\n",
            "Epoch 29/50\n",
            "125222/125222 [==============================] - 354s 3ms/sample - loss: 0.0455 - sparse_categorical_accuracy: 0.9881 - val_loss: 0.0700 - val_sparse_categorical_accuracy: 0.9871\n",
            "Epoch 30/50\n",
            "125222/125222 [==============================] - 357s 3ms/sample - loss: 0.0446 - sparse_categorical_accuracy: 0.9884 - val_loss: 0.0700 - val_sparse_categorical_accuracy: 0.9872\n",
            "Epoch 31/50\n",
            "125222/125222 [==============================] - 354s 3ms/sample - loss: 0.0438 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0693 - val_sparse_categorical_accuracy: 0.9873\n",
            "Epoch 32/50\n",
            "125222/125222 [==============================] - 357s 3ms/sample - loss: 0.0431 - sparse_categorical_accuracy: 0.9887 - val_loss: 0.0698 - val_sparse_categorical_accuracy: 0.9874\n",
            "Epoch 33/50\n",
            "125222/125222 [==============================] - 354s 3ms/sample - loss: 0.0423 - sparse_categorical_accuracy: 0.9889 - val_loss: 0.0695 - val_sparse_categorical_accuracy: 0.9875\n",
            "Epoch 34/50\n",
            "125222/125222 [==============================] - 357s 3ms/sample - loss: 0.0416 - sparse_categorical_accuracy: 0.9891 - val_loss: 0.0686 - val_sparse_categorical_accuracy: 0.9876\n",
            "Epoch 35/50\n",
            "125222/125222 [==============================] - 354s 3ms/sample - loss: 0.0410 - sparse_categorical_accuracy: 0.9893 - val_loss: 0.0689 - val_sparse_categorical_accuracy: 0.9877\n",
            "Epoch 36/50\n",
            "125222/125222 [==============================] - 356s 3ms/sample - loss: 0.0402 - sparse_categorical_accuracy: 0.9895 - val_loss: 0.0679 - val_sparse_categorical_accuracy: 0.9878\n",
            "Epoch 37/50\n",
            "125222/125222 [==============================] - 354s 3ms/sample - loss: 0.0397 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.0692 - val_sparse_categorical_accuracy: 0.9878\n",
            "Epoch 38/50\n",
            "125222/125222 [==============================] - 357s 3ms/sample - loss: 0.0392 - sparse_categorical_accuracy: 0.9897 - val_loss: 0.0689 - val_sparse_categorical_accuracy: 0.9877\n",
            "Epoch 39/50\n",
            "125222/125222 [==============================] - 354s 3ms/sample - loss: 0.0386 - sparse_categorical_accuracy: 0.9899 - val_loss: 0.0681 - val_sparse_categorical_accuracy: 0.9879\n",
            "Epoch 40/50\n",
            "125222/125222 [==============================] - 357s 3ms/sample - loss: 0.0382 - sparse_categorical_accuracy: 0.9900 - val_loss: 0.0683 - val_sparse_categorical_accuracy: 0.9880\n",
            "Epoch 41/50\n",
            "125222/125222 [==============================] - 354s 3ms/sample - loss: 0.0375 - sparse_categorical_accuracy: 0.9902 - val_loss: 0.0683 - val_sparse_categorical_accuracy: 0.9881\n",
            "Epoch 42/50\n",
            "125222/125222 [==============================] - 357s 3ms/sample - loss: 0.0370 - sparse_categorical_accuracy: 0.9902 - val_loss: 0.0683 - val_sparse_categorical_accuracy: 0.9880\n",
            "Epoch 43/50\n",
            "125222/125222 [==============================] - 354s 3ms/sample - loss: 0.0369 - sparse_categorical_accuracy: 0.9903 - val_loss: 0.0681 - val_sparse_categorical_accuracy: 0.9882\n",
            "Epoch 44/50\n",
            "125222/125222 [==============================] - 357s 3ms/sample - loss: 0.0364 - sparse_categorical_accuracy: 0.9904 - val_loss: 0.0682 - val_sparse_categorical_accuracy: 0.9882\n",
            "Epoch 45/50\n",
            "125222/125222 [==============================] - 354s 3ms/sample - loss: 0.0359 - sparse_categorical_accuracy: 0.9905 - val_loss: 0.0682 - val_sparse_categorical_accuracy: 0.9882\n",
            "Epoch 46/50\n",
            "125222/125222 [==============================] - 357s 3ms/sample - loss: 0.0355 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.0679 - val_sparse_categorical_accuracy: 0.9883\n",
            "Epoch 47/50\n",
            "125222/125222 [==============================] - 354s 3ms/sample - loss: 0.0352 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.0681 - val_sparse_categorical_accuracy: 0.9883\n",
            "Epoch 48/50\n",
            "125222/125222 [==============================] - 356s 3ms/sample - loss: 0.0348 - sparse_categorical_accuracy: 0.9908 - val_loss: 0.0680 - val_sparse_categorical_accuracy: 0.9883\n",
            "Epoch 49/50\n",
            "125222/125222 [==============================] - 354s 3ms/sample - loss: 0.0343 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0678 - val_sparse_categorical_accuracy: 0.9884\n",
            "Epoch 50/50\n",
            "125222/125222 [==============================] - 357s 3ms/sample - loss: 0.0341 - sparse_categorical_accuracy: 0.9910 - val_loss: 0.0680 - val_sparse_categorical_accuracy: 0.9884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp2G6QgE74WX",
        "colab_type": "code",
        "outputId": "e467ee56-cca3-4dad-b4ec-17e48b53336e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# Plot the results of the training.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label=\"Training loss\")\n",
        "plt.plot(history.history['val_loss'], label=\"Validation loss\")\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCincRUSqkMJdRKQKKdxFRKrQ/wevTzWUJI9o9gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5-UamSb8G3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Create the encoder model from the tensors we previously declared.\n",
        "encoder_model = Model(encoder_inputs, [encoder_out, state_h, state_c])\n",
        "\n",
        "# Generate a new set of tensors for our new inference decoder. Note that we are using new tensors, \n",
        "# this does not preclude using the same underlying layers that we trained on. (e.g. weights/biases).\n",
        "\n",
        "inf_decoder_inputs = Input(shape=(None,), name=\"inf_decoder_inputs\")\n",
        "# We'll need to force feed the two state variables into the decoder each step.\n",
        "state_input_h = Input(shape=(units*2,), name=\"state_input_h\")\n",
        "state_input_c = Input(shape=(units*2,), name=\"state_input_c\")\n",
        "decoder_res, decoder_h, decoder_c = decoder_lstm(\n",
        "    decoder_emb(inf_decoder_inputs), \n",
        "    initial_state=[state_input_h, state_input_c])\n",
        "inf_decoder_out = decoder_d2(decoder_d1(decoder_res))\n",
        "inf_model = Model(inputs=[inf_decoder_inputs, state_input_h, state_input_c], \n",
        "                  outputs=[inf_decoder_out, decoder_h, decoder_c])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjvkGbFG8Lqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converts the given sentence (just a string) into a vector of word IDs\n",
        "# Output is 1-D: [timesteps/words]\n",
        "\n",
        "def sentence_to_vector(sentence, lang):\n",
        "\n",
        "    pre = sentence\n",
        "    vec = np.zeros(len_input)\n",
        "    sentence_list = [lang.word2idx[s] for s in pre.split(' ')]\n",
        "    for i,w in enumerate(sentence_list):\n",
        "        vec[i] = w\n",
        "    return vec\n",
        "\n",
        "# Given an input string, an encoder model (infenc_model) and a decoder model (infmodel),\n",
        "def translate(input_sentence, infenc_model, infmodel):\n",
        "    sv = sentence_to_vector(input_sentence, input_lang)\n",
        "    sv = sv.reshape(1,len(sv))\n",
        "    [emb_out, sh, sc] = infenc_model.predict(x=sv)\n",
        "    \n",
        "    i = 0\n",
        "    start_vec = target_lang.word2idx[\"<start>\"]\n",
        "    stop_vec = target_lang.word2idx[\"<end>\"]\n",
        "    \n",
        "    cur_vec = np.zeros((1,1))\n",
        "    cur_vec[0,0] = start_vec\n",
        "    cur_word = \"<start>\"\n",
        "    output_sentence = \"\"\n",
        "\n",
        "    while cur_word != \"<end>\" and i < (len_target-1):\n",
        "        i += 1\n",
        "        if cur_word != \"<start>\":\n",
        "            output_sentence = output_sentence + \" \" + cur_word\n",
        "        x_in = [cur_vec, sh, sc]\n",
        "        [nvec, sh, sc] = infmodel.predict(x=x_in)\n",
        "        cur_vec[0,0] = np.argmax(nvec[0,0])\n",
        "        cur_word = target_lang.idx2word[np.argmax(nvec[0,0])]\n",
        "    return output_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQuHwOof8QjF",
        "colab_type": "code",
        "outputId": "d3a8908d-d9a2-42fe-9af6-b974f668e48b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 926
        }
      },
      "source": [
        "#Note that only words that we've trained the model on will be available, otherwise you'll get an error.\n",
        "\n",
        "\n",
        "# test = [\n",
        "#     'hi there',\n",
        "#     'hell',\n",
        "#     'have a nice we',\n",
        "#     'let me ',\n",
        "#     'Let me kno',\n",
        "#     'this soun',\n",
        "#     'is this call going t',\n",
        "#     'A man si',\n",
        "#     'Dog bar',\n",
        "#     'blue sky',\n",
        "#     'book on a ta',\n",
        "#     'A man completes the fini',\n",
        "#     'A man holds a lar',\n",
        "#     'A young adult wea'\n",
        "# ]\n",
        "\n",
        "test = [\n",
        "    'A woman wearing a bl',\n",
        "    'A man wor',\n",
        "    'A man is instr',\n",
        "    'A city str',\n",
        "    'A large man wea',\n",
        "    'Man remov',\n",
        "    'Seve',\n",
        "    'person is atte',\n",
        "    'wearing je',\n",
        "    'standing out',\n",
        "    'people in different co',\n",
        "    'dog ru',\n",
        "    'biker is ri',\n",
        "    'Blond girl in a yel',\n",
        "    'A person is walking al',\n",
        "    'A you',\n",
        "    'A young fem',\n",
        "    'A young female i',\n",
        "    'A young female is si',\n",
        "    'A young female is sitting i',\n",
        "    'A young female is sitting in a c',\n",
        "    'A young female is sitting in a chair o',\n",
        "    'A young female is sitting in a chair on th',\n",
        "    'A young female is sitting in a chair on the be',\n",
        "    'A young female is sitting in a chair on the beach , wh'\n",
        "]\n",
        "  \n",
        "\n",
        "import pandas as pd\n",
        "output = []  \n",
        "for t in test:  \n",
        "  output.append({\"Input seq\":t.lower(), \"Pred. Seq\":translate(t.lower(), encoder_model, inf_model)})\n",
        "\n",
        "results_df = pd.DataFrame.from_dict(output) \n",
        "results_df.head(len(test))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input seq</th>\n",
              "      <th>Pred. Seq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a woman wearing a bl</td>\n",
              "      <td>d hat and a young man wearing jean shorts and a gray tshirt are standing in front of a basketball carnival game on a blue and yellow checkered floor .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a man wor</td>\n",
              "      <td>ng in a skateboard jumping from a short ledge onto the sidewalk .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a man is instr</td>\n",
              "      <td>st riding a bike while wearing a helmet .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a city str</td>\n",
              "      <td>ntain with a blue shirt on his bmx bicycle .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a large man wea</td>\n",
              "      <td>r wearing a hat , and riding in a motorized wheelchair , is picking out shoes at a store .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>man remov</td>\n",
              "      <td>ng men in a city</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>seve</td>\n",
              "      <td>men wearing a large hat , are assembled outdoors .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>person is atte</td>\n",
              "      <td>en down a walkway at a house .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>wearing je</td>\n",
              "      <td>rs in plaid shirt scaling rocks .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>standing out</td>\n",
              "      <td>man in a suit wearing a green straw .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>people in different co</td>\n",
              "      <td>d a white shirt is standing on scaffolding reaching out to the ladder .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>dog ru</td>\n",
              "      <td>r in a building , a man with rolledup sleeves stands between two others wearing striped vests .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>biker is ri</td>\n",
              "      <td>le an airborne .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>blond girl in a yel</td>\n",
              "      <td>hat and a young man in an orange shirt pose for the camera .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>a person is walking al</td>\n",
              "      <td>le in a rundown looking area .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>a you</td>\n",
              "      <td>ng girl in a blue shirt stands next to a black man in a red robe .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>a young fem</td>\n",
              "      <td>le wearing a black hat and helmet is riding a skateboard field .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>a young female i</td>\n",
              "      <td>ng girls playing on the parallel bars .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>a young female is si</td>\n",
              "      <td>le in a pool with her hand on the edge of the pool and appears to be wearing a dark blue bathing suit and looking off to her right .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>a young female is sitting i</td>\n",
              "      <td>ng a bowling alley .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>a young female is sitting in a c</td>\n",
              "      <td>ood on a street .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>a young female is sitting in a chair o</td>\n",
              "      <td>ng the street in the water .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>a young female is sitting in a chair on th</td>\n",
              "      <td>r a crowd .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>a young female is sitting in a chair on the be</td>\n",
              "      <td>le in front of a large crowd .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>a young female is sitting in a chair on the beach , wh</td>\n",
              "      <td>le a man with a hat .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Input seq                                                                                                                                                Pred. Seq\n",
              "0   a woman wearing a bl                                     d hat and a young man wearing jean shorts and a gray tshirt are standing in front of a basketball carnival game on a blue and yellow checkered floor .\n",
              "1   a man wor                                                ng in a skateboard jumping from a short ledge onto the sidewalk .                                                                                     \n",
              "2   a man is instr                                           st riding a bike while wearing a helmet .                                                                                                             \n",
              "3   a city str                                               ntain with a blue shirt on his bmx bicycle .                                                                                                          \n",
              "4   a large man wea                                          r wearing a hat , and riding in a motorized wheelchair , is picking out shoes at a store .                                                            \n",
              "5   man remov                                                ng men in a city                                                                                                                                      \n",
              "6   seve                                                      men wearing a large hat , are assembled outdoors .                                                                                                   \n",
              "7   person is atte                                           en down a walkway at a house .                                                                                                                        \n",
              "8   wearing je                                               rs in plaid shirt scaling rocks .                                                                                                                     \n",
              "9   standing out                                              man in a suit wearing a green straw .                                                                                                                \n",
              "10  people in different co                                   d a white shirt is standing on scaffolding reaching out to the ladder .                                                                               \n",
              "11  dog ru                                                   r in a building , a man with rolledup sleeves stands between two others wearing striped vests .                                                       \n",
              "12  biker is ri                                              le an airborne .                                                                                                                                      \n",
              "13  blond girl in a yel                                       hat and a young man in an orange shirt pose for the camera .                                                                                         \n",
              "14  a person is walking al                                   le in a rundown looking area .                                                                                                                        \n",
              "15  a you                                                    ng girl in a blue shirt stands next to a black man in a red robe .                                                                                    \n",
              "16  a young fem                                              le wearing a black hat and helmet is riding a skateboard field .                                                                                      \n",
              "17  a young female i                                         ng girls playing on the parallel bars .                                                                                                               \n",
              "18  a young female is si                                     le in a pool with her hand on the edge of the pool and appears to be wearing a dark blue bathing suit and looking off to her right .                  \n",
              "19  a young female is sitting i                              ng a bowling alley .                                                                                                                                  \n",
              "20  a young female is sitting in a c                         ood on a street .                                                                                                                                     \n",
              "21  a young female is sitting in a chair o                   ng the street in the water .                                                                                                                          \n",
              "22  a young female is sitting in a chair on th               r a crowd .                                                                                                                                           \n",
              "23  a young female is sitting in a chair on the be           le in front of a large crowd .                                                                                                                        \n",
              "24  a young female is sitting in a chair on the beach , wh   le a man with a hat .                                                                                                                                 "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_10pgS38Udd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "45b639bf-80a9-46d5-c5e1-d110ed06d2c5"
      },
      "source": [
        "# This is to save the model for the web app to use for generation\n",
        "from keras.models import model_from_json\n",
        "from keras.models import load_model\n",
        "\n",
        "# serialize model to JSON\n",
        "#  the keras model which is trained is defined as 'model' in this example\n",
        "model_json = inf_model.to_json()\n",
        "\n",
        "\n",
        "with open(\"./drive/My Drive/ML/data/model_num_smart_compose_2500_50.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# serialize weights to HDF5\n",
        "inf_model.save_weights(\"./drive/My Drive/ML/data/model_num_smart_compose_2500_50.h5\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFqhnpFZeHgQ",
        "colab_type": "text"
      },
      "source": [
        "# Loading Existing Model for Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Dbj69wOeFzY",
        "colab_type": "code",
        "outputId": "7de28272-2856-4af7-c435-9dd18cab4f60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "#To mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FY7IXRneF-T",
        "colab_type": "code",
        "outputId": "c4f99437-8f6c-4ff0-f821-a47dfdaedcac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Start by importing all the things we'll need.\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, CuDNNLSTM, Flatten, TimeDistributed, Dropout, LSTMCell, RNN, Bidirectional, Concatenate, Layer\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.python.keras.utils import tf_utils\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, os \n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p__nfhJieGFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from keras.models import model_from_json\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP1tKGYMeGJO",
        "colab_type": "code",
        "outputId": "10b05883-c67e-452b-952d-cfc1e48e3ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        }
      },
      "source": [
        "# load json and create model\n",
        "json_file = open('./drive/My Drive/ML/data/model_num.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"./drive/My Drive/ML/data/model_num.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNN' used by {{node cu_dnnlstm_3/CudnnRNN}}with these attrs: [seed=0, dropout=0, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"lstm\", is_training=true, seed2=0]\nRegistered devices: [CPU, XLA_CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[cu_dnnlstm_3/CudnnRNN]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d6c0aad318ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# load weights into new model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./drive/My Drive/ML/data/model_num.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded model from disk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m    160\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    161\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   1422\u001b[0m         \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1424\u001b[0;31m         \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    757\u001b[0m                        str(len(weight_values)) + ' elements.')\n\u001b[1;32m    758\u001b[0m     \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m   \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3069\u001b[0m           \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3070\u001b[0m           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3071\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    460\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    877\u001b[0m     \u001b[0;31m# marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m     is_initialized = session.run(\n\u001b[0;32m--> 879\u001b[0;31m         [variables_module.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    880\u001b[0m     \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1368\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNN' used by node cu_dnnlstm_3/CudnnRNN (defined at <ipython-input-4-d6c0aad318ac>:4) with these attrs: [seed=0, dropout=0, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"lstm\", is_training=true, seed2=0]\nRegistered devices: [CPU, XLA_CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[cu_dnnlstm_3/CudnnRNN]]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCwwvVaJeGMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFE9eyAyeGPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTdUt__J9UFd",
        "colab_type": "code",
        "outputId": "d603ece0-6438-4ef4-fb84-82b62b5802a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        }
      },
      "source": [
        "\n",
        "# load json and create model\n",
        "json_file = open('./drive/My Drive/ML/data/model_num.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"./drive/My Drive/ML/data/model_num.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0906 06:30:03.488031 139718867613568 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0906 06:30:03.497553 139718867613568 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0906 06:30:03.498520 139718867613568 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0906 06:30:03.500934 139718867613568 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0906 06:30:03.503874 139718867613568 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNb2tL46SAo1",
        "colab_type": "code",
        "outputId": "7ab7f1c1-d99c-4b32-f71f-1bbd57b87ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        }
      },
      "source": [
        "# Create the encoder model from the tensors we previously declared.\n",
        "encoder_model = Model(encoder_inputs, [encoder_out, state_h, state_c])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2e23f4cf11b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoder_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mencoder_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'encoder_inputs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPTjVDtBOBpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Note that only words that we've trained the model on will be available, otherwise you'll get an error.\n",
        "\n",
        "# test = [\n",
        "#     'hi there',\n",
        "#     'hell',\n",
        "#     'presentation please fin',\n",
        "#     'resignation please find at',\n",
        "#     'resignation please ',\n",
        "#     'have a nice we',\n",
        "#     'let me ',\n",
        "#     'promotion congrats ',\n",
        "#     'christmas Merry ',\n",
        "#     'please rev',\n",
        "#     'please ca',\n",
        "#     'thanks fo',\n",
        "#     'Let me kno',\n",
        "#     'Let me know if y',\n",
        "#     'this soun',\n",
        "#     'is this call going t'\n",
        "# ]\n",
        "\n",
        "test = [\n",
        "    'A woman wearing a bl',\n",
        "    'A man wor',\n",
        "    'A man is instr',\n",
        "    'A city str',\n",
        "    'A large man wea',\n",
        "    'Man remov',\n",
        "    'Seve',\n",
        "    'person is atte',\n",
        "    'wearing je',\n",
        "    'standing out',\n",
        "    'people in different co',\n",
        "    'dog ru',\n",
        "    'biker is ri',\n",
        "    'Blond girl in a yel',\n",
        "    'A person is walking al',\n",
        "    'A you',\n",
        "    'A young fem',\n",
        "    'A young female i',\n",
        "    'A young female is si',\n",
        "    'A young female is sitting i',\n",
        "    'A young female is sitting in a c',\n",
        "    'A young female is sitting in a chair o',\n",
        "    'A young female is sitting in a chair on th',\n",
        "    'A young female is sitting in a chair on the be',\n",
        "    'A young female is sitting in a chair on the beach , wh'\n",
        "]\n",
        "  \n",
        "import pandas as pd\n",
        "output = []  \n",
        "for t in test:  \n",
        "  output.append({\"Input seq\":t.lower(), \"Pred. Seq\":translate(t.lower(), encoder_model, loaded_model)})\n",
        "  \n",
        "results_df = pd.DataFrame.from_dict(output) \n",
        "results_df.head(len(test))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}